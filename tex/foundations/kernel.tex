% Overview chapter
% Naive Set Theory
% Types
% Terms
% Theorems

\chapter{Overview} 

   What are the foundations of mathematics?  The foundations provide a {\it language} in which mathematics can be expressed precisely.  They specify {\it rules of logic} that give the accepted paths of reasoning about mathematics.  Finally, they assert {\it axioms}, or statements that may be accepted without proof.  Axioms give us a starting point for our logical reasoning.

  The foundational system can be expanded upon, by adding additional definitions, theorems, and proofs.

\section{Why do we need foundations?}

\subsection{consistency}

Frege devoted his life to the development of a logically coherent mathematical system.  His system was shattered in 1900 when B. Russell discovered an inconsistency in Frege's system.  

Here is Russell's paradox.  In Frege's system, it may be possible for a set to be an element of itself.  When this holds we write $Y\in Y$.  When it is not an element of itself, write $Y\not\in Y$.   We define $X$ to be the set of all sets $Y$ such that $Y\not\in Y$.  That is,
    $$X = \{Y\mid Y\not\in Y\}.$$
We ask, whether $X$ is an element of itself.    If $X\in X$, then $X$ satisfies the membership condition $Y\not\in Y$ to belong to $X$;  that is, $X\not\in X$.
If on the other hand $X\not\in X$, then $X$ does not satisfy the membership condition $Y\not\in Y$ to belong to $X$; that is, $X\in X$.  So $X$ is a member of itself, if and only if it is not a member of itself.  This is a contradiction in Frege's system.

\subsection{settle disputes}

Sometimes arguments arise about whether a proof is correct or not.  The problem is usually that the proof has been written in a way that is far from the foundations of mathematics.  By reworking the proof to make its connection with the foundations more transparent, the dispute can generally be resolved.

\subsection{unification of mathematics}

Different branches of mathematics can be seen from a unified perspective from the foundations of mathematics.  Calculus, analysis, differential equations, algebra, group theory, topology, geometry, applied mathematics, etc. can be all be treated as part of a coherent whole, unified by the foundations.

\subsection{formal proofs}

It has become possible in recent years for computers to check every step of mathematical proofs.  A proof at the foundational level is called a {\it formal proof}.  The computer systems that check proofs in this way must be based on the foundations of mathematics.

\section{various systems}

There are many foundational systems of mathematics that have been developed.

\subsection{Zermelo set theory}

Russell's paradox prompted mathematicians to develop a consistent system of axioms for doing mathematics.  Many foundational systems are based on set theory.  A system of axioms for doing set theory was developed by the mathematician Zermelo in 1908.   This is Zermelo set theory.  This book does not go into details about Zermelo set theory, but we will have occasion to use it.  

Later Zermelo set theory was supplemented in various ways.  The mathematician Fraenkel added one more axiom to the system (called the axiom of replacement).  One further axiom (the axiom of choice) was added.  Zermelo set theory, supplemented by these two further axioms, is called Zermelo-Fraenkel-Choice set theory; or simply ZFC set theory.

\subsection{Bourbaki}

In the 1940s a group of French mathematicians banded together under the pseudonym, General Nicholas Bourbaki.  They developed a system of set theory, and gave a careful description of major branches of mathematics within a coherent framework.  Bourbaki has come to represent an approach to mathematics which is abstract, general, and systematic.

\subsection{Higher Order Logic}

This book develops a system of higher-order logic for a foundational system.  The origins of this system can be traced to the work of Alonzo Church.  We will not say more about it now, because the entire book will be devoted to developing this system.

\subsection{others}


In fact, there have been many different foundational systems that have been proposed over the past decades.  There is nothing to stop anyone from proposing a new system of axioms for doing mathematics.


\section{How to choose?}

\subsection{analogy}

What foundational system should we use?

We face a similar question when we purchase a computer.  What computer to buy?  Different computers run different operating systems, such as UNIX, Linux, Windows, or Mac OS X.  Some become fanatical about what brand is best or what operating system is best.  Others go with whatever other people seem to be using.

No matter what computer or operating system we decide upon, we expect it to have certain basic capabilities.  It should have a web browser.  It should be capable of reading the hard drive, and downloading files.  It should be possible to edit documents and to print files.  It should be possible to set up user accounts.

We can make analogous statements about a foundational system.  There are
many products to choose from (Zermelo, Bourbaki, Higher-Order Logic, etc).  Some people may become fanatically devoted to a particular system and others may go with whatever others seem to be using.  No matter what system we choose to use, it should have certain basic capabilities.  It should be possible to do basic logic.  It should be possible to develop the properties of standard number systems such as the natural numbers, rational numbers, and real numbers.  It should be possible to do calculus, analysis, algebra, topology, and geometry within the system.  Applied mathematics should be possible.  it should be possible to do calculations in an efficient way.

\subsection{Why HOL?}

The most popular system among mathematicians in ZFC.  This is largely a result of historical developments, rather than any compelling reason.  The ZFC system has the first-to-market advantage, and has retained a large marked share through the decades.

The HOL system has a remarkably small number of fundamental mathematical axioms. (There are only three!)  It can be elegantly implemented in computer code, and this makes it a popular system for computer proof assistants.  It has a type system that makes it more difficult to write nonsensical formulas.  (More about the type system later.)  The logical operators (such as {\it not, and, or, iff} and quantifiers) are defined in terms of even more primitive functions.  It has higher-order features  that give it some of the same advantages as functional programming languages.




\section{immersion}

Again, we start with an analogy.  Learning a foundational system is like learning a foreign language.  In a foreign language course, the student can learn by immersion or through the native language.  

In an immersion course, the student jumps into the water to sink or swim, without support from a native langauge.  Suppose the student is learning Vietnamese.  In an immersion course, neither the teacher nor the student speaks a word of English inside the classroom.  The student learns the meanings of Vietnamese words by gestures, pantomimes, and grunts.  An infant learns a language by immersion.  

By contrast, when a language is taught by means of the speaker's native language, two languages are spoken in the classroom.  If a native English speaker learns Vietnamese, both English and Vietnamese are spoken:  English for instruction about  Vietnamese.   The langauge being acquired is the {\it target language}.  The instructional language is called the {\it meta language}.  In this example, English is the meta language, and Vietnamese the target language.  (We could also teach English to Vietnamese students.  Here English becomes the target language and Vietnamese becomes the meta language.)  Once the student has reached a certain stage in the study of Vietnamese, it is natural to exclude the meta language English from the classroom, and to do everything in Vietnamese.

We face a similar situation when we learn a new foundational system in mathematics.  The immersion approach is not successful.  It is not really possible to teach advanced mathematics by gestures, pantomimes, and grunts.  We will use a two language system.  We will assume that the reader of this book already has an informal knowledge of mathematics.  We will use that informal system to describe the new langauge.  We will have a meta mathematics (which is the instructional mathematical language), and a target mathematics (which is the new mathematical system we are learning).  
Just as it is important not to confound English with Vietnamese, it is important not to confound the meta mathematical system with the target system.

This book uses Zermelo set theory as the metamathematical system.  Zermelo set theory is used because it is currently the the most widespread mathematical system.  Only simple properties of Zermelo set theory will be used.  The target mathematical system is Higher Order Logic (HOL).  

In mathematics, there is a greater danger of confounding the metamathematical system with the target mathematical system, because some of the symbols will be the same in both systems.  For example, the natural number \verb!0! will exist as both a set in Zermelo set theory and as a term in Higher Order Logic.   Our convention will be to distinguish terms in the target Higher Order Logic with backquotes.  For example, \verb!`0`! denotes the term in Higher-Order Logic and \verb!0! denotes a set in Zermelo set theory.

We use the terms {\it metalanguage}, {\it metalogic}, and {\it metamathematics} to refer to the familiar informal language, logic, and math that is being used to construct the system of Higher Order Logic.  We use the terms {\it HOL language}, {\it HOL logic}, and {\it HOL mathematics} to refer to the target foundational system of Higher Order Logic. 


\chapter{Naive Set Theory}

This chapter gives a review of basic set theory.  We only present enough set theory to make sense of the metamathematical constructions in this book.
The book assumes an elementary knowledge of the theory of sets.  

The set of greatest interest to us is the set of natural numbers:
$$
\mc{\ring{N}=\{0,1,2,3,4,5,\ldots\}}.
$$


\section{notation}


\subsection{prefix}

Generally, a function is written before the input to the function:
\mc{$f(x)$} indicates the value of a function \mc{$f$} that has been evaluated
at an element \mc{$x$} of its domain.  This is called {\it prefix} notation
because the function \mc{$f$} appears before the element \mc{$x$}.  
In this book, the parentheses around the input  to the function are optional;
juxtaposition is function application:
$f(x) = f~x$.

\subsection{postfix}

When the function is written after the input, as in \mc{$x f$} for the value of the function on the input \mc{$x$}, it is called postfix notation.  For example, the factorial function \mc{$5! = 5\times 4\times 3\times2\times 1 = 120$}, is a function denoted with the symbol \mc{$!$} in postfix notation.   We will generally avoid this notation.

\subsection{infix}

Finally, if the function is a function of two variables \mc{$x$} and \mc{$y$}, and the function symbol is written between the two variables, it is called {\it infix} notation.  This appears as \mc{$x\,f\, y$}.    The infix notation often appears with functions that have symbolic names, such as addition of natural numbers.  The function is written in infix position:
  \mc{$$x + y.$$}

Here are some examples of infix operators.
\mc{$$
3+4,\ 7\times 8,\ 10/2,\ 4 - 3,\ 2 < 7,\ 8\ge 6,\ X\subset Y, \hbox{ and } \ x\in A.
$$}

There are times when we wish to convert infix notation into prefix.  To do so, we place parentheses around the infix function.   For example
\mc{$$
x + y
$$
}
is a notational variant of
\mc{
$$
(+)~x~y.
$$
}
Following this convention, we have the following notation variants:
\mc{
$$
\begin{array}{lll}
\hbox{prefix} & \hbox{infix}\\
(+)~3~4 & 3 + 4\\
(/)~10~2 & 10/2\\
(\ge)~8~6 & 8 \ge 6\\
(\times)~7~8 & 7\times 8\\
\end{array}
$$
}

To say that we have a notational variant means that the two expressions have the same denotation.  


\subsection{right associative}

If \mc{$*$} is an infix operator, then \mc{$a * b * c$} is ambiguous.  It can mean
either \mc{$(a* b)*c$} or \mc{$a*(b*c)$}.  One way to resolve the ambiguity is to insert the parentheses.  Another way to resolve the ambiguity is to declare the infix operator to  be right-associative or left-associative.  If an operator is
declared to be right associative then the parentheses are inserted from the right:
\mc{
$$
a*b*c*d = a*(b*(c*d)),\quad \hbox{right associative}
$$
}
An infix operator declared to be left-associative requires the parentheses to be inserted from the left:
\mc{
$$
a*b*c*d = ((a*b)*c)*d.\quad \hbox{left associative}
$$
}

The distinction between prefix, infix, and postfix can be made at both the mathematical level and at the metamathematical level.  The same holds of right-associative and left-associative.



\section{sets}

The set with no elements is called the {\it empty set} and is denoted \mc{$\emptyset$} or \mc{$\{\}$}.
A set \mc{$\{a\}$} that contains exactly one element \mc{$a$} is called a {\it singleton set}.  Other sets can be formed by listing their elements:
\mc{$$
\{0,2,4,6\}
$$}

\subsection{extensionality}

We write \mc{$x\in A$} to mean that \mc{$x$} is {\it an element of} \mc{$A$}.  A set can be conceived as a of container of elements.  The {\it axiom of extensionality} for sets asserts that two sets are equal if and only if they contain the same elements:
  \mc{
   $$(A = B)\hbox{ if and only if } \forall x.\ (x\in A) \Leftrightarrow (x\in B).$$}
For example,
   \mc{$$\{1,2,3,4,4,3,2,2,2,2,1\} = \{4,3,2,1\} = \{1,2,3,4\}$$}
because \mc{$x$} is an element of this set precisely when \mc{$x=1,2,3$}, or \mc{$4$}.
Since they contain the same elements, they are equal.  The order of listing and the repetitions do not matter.

Two sets are distinct if the nesting of braces is different.
For example,
\mc{$$
\{\},\qquad \{\{\}\},\qquad \{\{\{\}\}\},\qquad \{\{\},\{\{\}\}\}
$$}
are all different sets from one another.  The first is the empty set.
The second is a set with one element.  That element is the empty set.
The third is a set with one element.  That element is the second set in the list.  The final set contains two distinct elements: the empty set and the singleton set with the empty set as its only element.  Sets like these can be conceived as containers nested within other containers.

\subsection{comprehension}

If \mc{$A$} is a set, we write
\mc{$$
\{x \in A \mid P(x)\}
$$}
for the set of all elements in A that satisfy the property \mc{$P$}.
For example,
\mc{$$
\{x\in\ring{N} \mid x > 3 \hbox{ and } x < 7\} = \{4,5,6\}.
$$}



We write \mc{$A\subset B$} to mean that every element of \mc{$A$} is an element of \mc{$B$}. We write \mc{$A\cap B$} for the set of all elements that belong to both \mc{$A$} and \mc{$B$}:
\mc{
$$
A\cap B = \{x \mid x\in A\hbox{ and } x \in B\}.
$$
}
The set \mc{$A\cap B$} is called the {\it intersection} of \mc{$A$} and \mc{$B$}. We write \mc{$A\cup B$} for the set of all elements that belong to either \mc{$A$} or \mc{$B$}:
\mc{$$
A\cup B = \{x\mid x\in A\hbox{ or } x\in B\}.
$$}
The set \mc{$A\cup B$} is called the {\it union} of \mc{$A$} and \mc{$B$}.
For example, if \mc{$A=\{1,2,3\}$} and \mc{$B = \{3,4\}$}, then
\mc{$$
A\cap B = \{3\},\quad A\cup B = \{1,2,3,4\}.
$$}

\subsection{powerset}

Given any set \mc{$X$}, there is a set \mc{$P(X)$}, called the {\it powerset} of \mc{$X$} whose elements are  all the subsets of \mc{$X$}:
\mc{$$
P(X) = \{x\mid (x\in P(X))\Leftrightarrow (x\subset X)\}.
$$}
For example, if \mc{$X = \{1,2,3\}$}, then \mc{$P(X)$} is the following set with
\mc{$2^3 = 8$} elements:
\mc{$$P(X) = \{\emptyset, \quad \{1\},\{2\},\{3\},\quad
          \{1,2\},\{2,3\},\{1,3\},\quad \{1,2,3\} \}.$$}


Zermelo's axioms of set theory insure that \mc{$A\cup B$}, \mc{$A\cap B$}, \mc{$P(X)$} always exist.

\subsection{ordered pairs}

Given any \mc{$x$} and \mc{$y$}, there is a set \mc{$(x,y)$} called the ordered pair
of \mc{$x$} and \mc{$y$}.  It has the property that \mc{$(x,y)=(a,b)$} if and only if
\mc{$$
x = a \quad \hbox{ and } y = b.
$$}
Given any sets \mc{$X$} and \mc{$Y$}, there is a set \mc{$X \times Y$} called the Cartesian product of \mc{$X$} and \mc{$Y$}, consisting of all ordered pairs whose first element belongs to \mc{$X$} and second element belongs to \mc{$Y$}:
\mc{$$
X\times Y  = \{(x,y) \mid x\in X\hbox{ and } y \in Y\}.
$$}
For example, if \mc{$X = \{0,1\}$} and \mc{$Y=\{2,3\}$}, then
\mc{$$
X\times Y = \{(0,2),(0,3),(1,2),(1,3)\}.
$$}

There are functions \mc{$\fst:X\times Y\to X$} and \mc{$\snd:X\times Y\to Y$} that return the first and second part of an ordered pair:
\mc{$$
\fst(x,y) = x\qquad \snd(x,y) = y.
$$}

An ordered triple \mc{$(x,y,z)$} is alternate notation for \mc{$(x,(y,z))$}.  (That is, the comma is right-associative.)  An ordered quadruple \mc{$(w,x,y,z)$} is an alternate notation for \mc{$(w,(x,(y,z)))$}.  









\section{curried functions}

We write \mc{$Y^X$} for the set of all functions from \mc{$X$} to \mc{$Y$}.  In other
words, \mc{$Y^X$} is the set of all functions with domain \mc{$X$} and range \mc{$Y$}.
In Zermelo set theory, there is a bijection of sets between
\mc{\begin{equation}
  Z^{X\times Y}\hbox { and } (Z^Y)^X.\label{eqn:curry}
\end{equation}}
That is, there is a bijection between functions with domain is the Cartesian product \mc{$X\times Y$} and range \mc{$Z$} on the one hand, and functions whose domain is \mc{$X$} and range is the set of functions from \mc{$Y$} to \mc{$Z$} on the other hand.
(Notice the formal similarity with the law of exponents for natural numbers:
\mc{$z^{x y} = (z^y)^x$}.)

It may seem odd at first that the range of a function is a set of functions, but this will happen quite routinely in this book.

The bijection is given explicity as follows.  If \mc{$b:X\to Z^Y$} is a function
on the right-hand side of (\ref{eqn:curry}), then let \mc{$f_b:X\times Y\to Z$}
be the function given by 
\mc{$$
f_b(x,y) = b(x) (y).
$$}
In the other direction, if \mc{$a:X\times Y\to Z$} is a function on the left-hand side of (\ref{eqn:curry}), then let \mc{$h_a:X\to Z^Y$} be given by
\mc{$$
h_a(x) = (y\mapsto a(x,y)).
$$}
Note that \mc{$h_a(x)$} is a function from \mc{$Y$} to \mc{$Z$}.
It can be  checked that \mc{$a\mapsto h_a$} and \mc{$b\mapsto f_b$} are inverse functions of one another and give the bijection asserted in (\ref{eqn:curry}).
That is,
\mc{$$
f_{h_a} = a,\hbox{ and } h_{f_b} = b.
$$}

This bijection will be extremely important for the developments in this book.  The right-hand side of the bijection (\ref{eqn:curry}) is called the curried form of the function.  The left-hand side of the bijection (\ref{eqn:curry}) is called the uncurried form of the function.  (The name comes from the logician Haskell Curry.)   In the vast majority of all situations, we prefer to use the curried form of the function.  We prefer curried functions in both the metamathematical system and the HOL mathematical system.

\begin{example}[addition]
As an example, let us analyze addition of natural numbers.  The addition operator in uncurried form takes an ordered pair \mc{$(x,y)$} and
returns the sum \mc{$x+y$}.   Now consider addition as a curried function and analyze the expression \mc{$3+4$}.  For example, we can write this in curried prefix notation as
\mc{$$
(+)~3~4.
$$}
Curried addition is a function in \mc{$(\ring{N}^{\ring{N}})^{\ring{N}}$}.  The domain
is the set of natural numbers and the range is a function from \mc{$\ring{N}$} to \mc{$\ring{N}$}.
That is \mc{$(+)~3$} is a function from \mc{$\ring{N}$} to \mc{$\ring{N}$}.  This function is the function that adds \mc{$3$}; that is, \mc{$(+)~3 = (y\mapsto y+3)$}.  We apply the
the function that adds \mc{$3$} to \mc{$4$} and the result is \mc{$7$}.
\end{example}

Explained somewhat differently, the uncurried function takes everything at once and the curried function takes its inputs one at a time.  We can take \mc{$(3,4)$} together and return the sum \mc{$7$} in uncurried form.  In curried form, we can take \mc{$3$}, then take a pause or even a long siesta before taking the \mc{$4$}, finally returning the \mc{$7$}.  In curried form, we can even stop entirely before evaluating the function \mc{$(+)~3$} on the second summand, and leave it in this form as the function that adds \mc{$3$}.

\subsection{unwrapping the exponents}

We have introduced the notation \mc{$(Z^Y)^X$} for the set of functions with domain \mc{$X$} and range \mc{$Z^Y$}.    If \mc{$b$} is such a function, we can write it
\mc{$b:X\to Z^Y$} to indicate its domain \mc{$X$} and range \mc{$Z^Y$}.  When we take
\mc{$b(x)$} we get a function \mc{$Y\to Z$}.  If we unwrap the exponents, we
take an element of \mc{$X$} then an element of \mc{$Y$} to get an element of \mc{$Z$}.
Thus, it is natural to write
\mc{$$
b:X\to Y\to Z\quad \hbox{ or }\quad  
b:X\to (Y\to Z)
$$}
to indicate the domain and range of \mc{$b$}.  The expression on the left
says we take \mc{$x\in X$} then \mc{$y\in Y$} and return \mc{$z\in Z$}.  On the
right, we take \mc{$x\in X$} then return a function \mc{$Y\to Z$}.

Because of this example, we adopt the convention that the arrow \mc{$\to$}
is to be right associative:
\mc{$$
X\to Y \to Z = X\to (Y\to Z).
$$}
The uncurried form of a function \mc{$b:X\to Y\to Z$} is \mc{$f_b:(X\times Y)\to Z$}.
If we want to use a function \mc{$c$} whose domain is \mc{$Y^X$} and range is \mc{$Z$},
the parentheses must be inserted explicitly: \mc{$c:(X\to Y)\to Z$}.

\subsection{parentheses}

The convention is to drop the parentheses on curried functions when this can be done without ambiguity.  For example, curried prefix addition is written
\mc{$$
(+)~x~y
$$}
rather than any of the following forms:
\mc{$$
(+)(x)(y)\quad ((+)(x))(y)  \quad (((+)(x))(y)).
$$}
These forms are correct, but contain unnecessarily many parentheses.
In this example, the parentheses are needed around the \mc{$(+)$} to make it
a prefix operator rather than an infix operator. All other parentheses may
be dropped.

\subsection{partial functions}

Sometimes functions are needed whose domain is a proper subset of a set \mc{$X$} to \mc{$Y$}.  With curried functions, it is often easier to extend the range than to restrict the domain to a proper subset.

If \mc{$Y$} is any set, let \mc{$Y^+$} be a set that contains \mc{$Y$} as a proper subset, and choose $\verb!error!\in Y^+\setminus Y$.  
If we have a function \mc{$f:X'\to Y$} defined on a proper subset \mc{$X'$} of \mc{$X$}, we can
extend it to a function \mc{$f^+:X\to Y^+$} by the rule:
\mc{$$
f^+(x) = \begin{cases} f(x) & x\in X'\\ \op{\tt error} & x\not\in X'\end{cases}.
$$}
The set \mc{$X'$} can be recovered as
\mc{$X'=\{x\in X\mid f(x)\in Y\}$}.








\section{natural numbers}

We let \mc{$\ring{N}=\{0,1,2,3,\ldots\}$} be the set of natural numbers. 
Zero $\mc{0}$ is a natural number.  From a metamathematical point of view, we are not interested in the set of natural numbers from a number theoretic point of view.  Rather, it is a set large enough (countably infinite) to contain all of the structures needed to do metamathematics.  Moreover, we know various facts about the set of natural numbers that make it a convenient choice. For example, this section will review the principle of mathematical induction for the natural numbers, and will state the recursion theorem for natural numbers.


\subsection{base}

Traditionally, natural numbers are denoted in base ten representation.  Ten digits are used to denote a natural number
$$
0\quad 1\quad 2\quad 3\quad 4\quad 5\quad 6\quad 7\quad 8\quad 9
$$
The position of each digit in a numeral determines its value:
$$
1728 = 1\times 10^3 + 7\times 10^2 + 2\times 10^1 + 8\times 10^0.
$$
To emphasize the base of the representation, the base can be appended as a subscript:
$$1728_{10}=1\times 10^3 + 7\times 10^2 + 2\times 10^1 + 8\times 10^0.$$

Through the widespread use of binary computers, bases that are powers of two have become increasingly prevalent.  The base two representation uses two digits
$$
0\quad 1
$$
Thus,
$$
1000101_2 = 1\times 2^6 + 0\times 2^5 + 0\times 2^4 + 0\times 2^3 + 1\times 2^2 + 0\times 2^1 +1 \times 2^0 = 69_{10}.
$$
The base sixteen representation uses sixteen digits in the following order:
$$
0\quad 1\quad 2\quad 3\quad 4\quad 5\quad 6\quad 7\quad 8\quad 9\quad
A\quad B\quad C\quad D\quad E\quad F
$$
Thus,
$$
\verb!E7C!_{16} = 14\times 16^2 + 7 \times 16^1 + 12\times 16^0 = 3708_{10}.
$$
The base $256$ representation of a natural number uses 256 digits, called {\it characters}.  
The $256$ digits are listed in a fixed order in a table called the ASCII character table.  The table includes the ten digits $0$ through $9$, the twenty-six lower case Roman alphabet $a$ through $z$, the twenty-six upper case Roman alphabet $A$ through $Z$, and common keyboard strokes such as:
$$
\verb#, ; . : ( ) { } [ ] < > - _ + / * @ % & ? ! #
$$
Each lower case Roman character is different from the corresponding upper-case character.
Thus,
$$
\verb!Rain!_{256} = 82\times 256^3 + 97\times 256^2 + 105\times 256^1 + 110\times 256^0 = 1382115694.
$$
and
% ToCharacterCode["rain"].{256^3, 256^2, 256^1, 1}
$$
\verb!rain!_{256} = 114\times 256^3 + 97\times 256^2 + 105\times 256^1 + 110\times 256^0 = 1918986606.
$$
An alternate notation for base $256$ numerals is enclosure in double quotation marks.  Thus,
$$
\verb!Rain!_{256} = \verb!"Rain"! = 1382115694_{10}
$$
In this notation, the enclosing quotation marks are not part of the numeral.  The double quotation mark is itself an ASCII character.  When a double quotation mark occurs as part of the numeral, we revert to the appended subscript notation:
$$
\verb!%3"#!_{256} = 37\times 256^3 + 51\times 256^2 + 34\times 256^1 + 35\times 256^0  = 624108067_{10}. 
$$
Some of the ASCII characters cannot be printed; there are characters for backspace, tab, carriage return, bell, and so forth.  Numerals with unprintable characters will be avoided in this text.



\subsection{serial pairs}

\begin{lemma}
There is a one-to-one function $\langle\cdot,\cdot\rangle:\ring{N}\times\ring{N}\to\ring{N}$ given by
$$
\langle x,y\rangle = (x+y)^2 + y + 1.
$$
\end{lemma}
We call \verb!<x,y>! a serial pair. A serialized triple is defined as a nested serial pair: \verb!<x,y,z> = <x,<y,z>>!.

\begin{exer} Show that if $\langle x,y\rangle = \langle x',y'\rangle$, then $x=x'$ and $y=y'$.
Hint: if $x+y < x'+y'$ then 
$$
\langle x,y\rangle\le (x+y)^2+(x+y) < (x'+y')^2 \le \langle x',y'\rangle.
$$
and if $x+y=x'+y'$ and $x<x'$, then again $\langle x,y\rangle < \langle x',y'\rangle$.
\end{exer}



\subsection{recursion}

A fundamental property of the natural numbers is that functions can be
defined by recursion.  We do not give the proof here, because recursion will be covered in much greater detail later.


%\begin{assert}[recursion]  For any sets $X$, $Y$, for any function $a:X\to Y$, and any function $b:\ring{N}\times X\times Y\to Y$, there exists a unique function $f:\ring{N}\times X\to Y$ such that
%$$
%\begin{array}{lll}
%f(0,x) &= a(x)\\
%f(n+1,x) &= b(n,x,f(n,x)),~\hbox{ for all } n\in\ring{N},~~ x\in X.
%\end{array}
%$$
%\end{assert}

%We do not give the proof here, because recursion will be covered in much greater detail later.  In the special case when $X$ is a singleton set $\{x\}$, the function $a:X\to Y$ is determined by the image $a'$ of $x$.  The function $b$ is determined by a function $b':\ring{N}\times Y\to Y$:
%$$
%b(n,x,y) = b'(n,y).
%$$
%This gives the following special form of recursion:

\begin{assert}[recursion]  For any set $Y$, for any element $a\in Y$, and any function $b:\ring{N}\times Y\to Y$, there exists a unique function $f:\ring{N}\to Y$ such that
$$
\begin{array}{lll}
f(0,x) &= a\\
f(n+1,x) &= b(n,f(n)),\hbox{ for all } n\in\ring{N}.
\end{array}
$$
\end{assert}



\subsection{lists}

We define by recursion, a function from $\ring{N}$ to subsets of the natural numbers.  A set in the image of $n\in\ring{N}$ is called a list of length $n$.  Let \verb!null=0! and \verb!cons=1!.

\begin{definition}
The set of lists of length $0$ is the singleton set \verb!{null}!.  By recursion, the set of  lists of length $n+1$ is the set
consisting of all  triples \verb!<cons,k,p>!, where $k\in\ring{N}$, and where \verb!p! is a  list of length $n$.   A  list is an element of the set of  lists of length $n$ for some $n$.  We let \verb!list! denote the set of all  lists.
\end{definition}

\begin{exer} Explicitly identify the element $a$ and function $b$ that are used in the recursive definition of  lists.
\end{exer}

\begin{exer} Show that every list has the form \verb!null! or the form \verb!<cons,_,_>! and that no list has both forms.
\end{exer}


\subsubsection{list operations}

\begin{exer}\label{exer:list-length} show that the set of  lists of length $n$ is disjoint from the set of  lists of length $n'$ for $n\ne n'$.
\end{exer}

\begin{definition} Let $p$ be a  list of length $n$.  We call $n$ the length of $p$ and write \verb!len p!.  By Exercise~\ref{exer:list-length}, the length is well defined.
\end{definition}


\begin{example}
\verb!<cons,3,<cons,4,<cons,5,null>>>!
is a  list.
\end{example}

\begin{definition} Define (provisionally)
\begin{verbatim}
head <cons,a,p> = a
head x = 0, otherwise.
\end{verbatim}
\end{definition}

\begin{exer}\label{ex:iter}  For any sets $A,B,C$, let \verb!(o):(B->C) -> (A->B) -> (A->C)! be the curried infix function that gives the composition \verb!f o g! of two functions \verb!f:A->B!, \verb!g:B->C!.  For any set $A$, define a function $\verb!iter:!\ring{N} \to (A\to A)\to(A\to A)$ by recursion such that
\begin{verbatim}
iter n f = f o f o f o ... o f   (n times)
\end{verbatim}
\end{exer}

\begin{exer} Define by recursion a function \verb!map! that takes a function $f:\ring{N}\to \ring{N}$ and a list $[a_0;\ldots;a_r]$ and returns the list
$[f~a_0;\ldots;f~a_r]$.
For example, if $f(x) = x+3$
\begin{verbatim}
map f [2;4;6] = [5;7;9].
\end{verbatim}
\end{exer}

\begin{exer} Define by recursion a function \verb!rev! that reverses the list.  For example,
\begin{verbatim}
rev [2;3;4] = [4;3;2].
\end{verbatim}
\end{exer}



\begin{definition}[setify]
Define a function \verb!f:list x P(N) -> list x P(N)! by
\begin{verbatim}
f(null,Y) = (null,Y)
f(<cons,a,p>,Y) = (p,Y UNION {a})
\end{verbatim}
Define a function \verb!setify:list -> P(N)! by
\begin{verbatim}
setify p = snd(iter (len p) f (p,{}))
\end{verbatim}
\end{definition}

\begin{example}
\begin{verbatim}
setify<cons,3,<cons,4,null>> = snd((f o f) (<cons,3,<cons,4,null>>,{})) 
  = snd(f(f(<cons,3,<cons,4,null>>,{}))) 
  = snd(f(<cons,4,null>,{3}))
  = snd(null,{3,4})
  = {3,4}
\end{verbatim}
\end{example}

We say that $x$ is a member of the  list $p$ if $x\in\verb!setify(p)!$.


\begin{notation} The  list \verb!null! is called the null list, and is written \verb![]!.  Others lists will be denoted by a sequence of natural numbers enclosed in square brackets and separated by parentheses, listed in the same order as the \verb!cons!es:
$$
\begin{array}{lll}
\hbox{shorthand notation} & \hbox{full form}\\
~[]&\verb!null!\\
~[3;4]&\verb!<cons,3,<cons,4,null>>!\\
~[2;1;1]&\verb!<cons,2,<cons,1,<cons,1,null>>>!\\
\end{array}
$$
\end{notation}

\subsubsection{merge}


\begin{exer}[itlist] We define  a function \verb!itlist! that takes a curried function $f:\ring{N} \to\ring{N} \to\ring{N}$, a list $p$, and $c\in \ring{N}$ and returns a natural number.  With the definition:
\begin{verbatim}
itlist f p a = snd(iter (len p) g (p,a)), where
g (null,c) = (null,c)
g (<cons,b,p>,c) = (p,f b c)
\end{verbatim}
Show that 
\begin{verbatim}
itlist f [] a = a,
itlist f <cons,b,p> a = f b (itlist f p a) 
\end{verbatim}
\end{exer}


Define an infix function
$$
\verb!(insert): nat -> list -> list!
$$
as \verb!x insert p = <cons,x,p>! if $x$ does not belong to $p$; and
\verb!x insert p = p! otherwise.


\begin{exer} Define by recursion a function (written in infix notation)
\begin{verbatim}
(union): list -> list -> list
(union) = itlist (insert) 
\end{verbatim}
that applies \verb!insert! to all of the entries of the first list. For example,
\begin{verbatim}
[1;1;3] union [2;3;3;4] 
 = 1 insert (1 insert (3 insert [2;3;3;4]))
 = [1;2;3;3;4].
\end{verbatim}
\end{exer}

%\begin{definition} 
%!\verb!r MERGE p = r union (p union [])!
%\end{definition}

%\begin{example}
%\begin{verbatim}
%[2;1;4;3;1] MERGE [2;1;3;2] 
% = [2;1;4;3;1] union ([2;1;3;2] union [])
% = [2;1;4;3;1] union [1;3;2]
% = [4;1;3;2]
%\end{verbatim}
%\end{example}


\subsubsection{complete recursion}

\begin{lemma}[complete recursion]  Let $a\in \ring{N}$ and let \verb!b:N x list -> N! be any functions.  Then there exists a unique function $f:\ring{N}\to\ring{N}$ such that
\begin{verbatim}
f(0)   = a
f(n+1) = b(n,[f(n);f(n-1);...;f(0)])
\end{verbatim}
\end{lemma}

\begin{proof}  Let $a' = [a]\in\op{\tt list}$ and \verb!b':N x list -> list! be the
function \verb!b'(n,p) = <cons,b(n,p),p>!.  Apply the recursion theorem to $a',b'$ to get a unique function \verb!F:N -> list! such that
\begin{verbatim}
F(0)   = [a]
F(n+1) = <cons,b(n,F(n)),F(n)>
\end{verbatim}
Define \verb!f n = head (F n)!
We prove by induction that \verb!F n = [f n; f (n-1); ... ; f 0]!
\begin{verbatim}
F 0 = [a] = [head (F 0)] = [f 0]
F (n+1) = <cons,b(n,F(n)),F n >
        = <cons,f (n+1),F n>
        = <cons,f (n+1),[f n;f (n-1); ... ; f 0]>  (induction step)
        = [f (n+1);...; f 0]
\end{verbatim}
The conclusion follows:
\begin{verbatim}
f 0 = head (F 0) = a
f (n+1) = head (F (n+1)) 
        = b(n,F(n))
        = b(n,[f n;....;f 0])
\end{verbatim}
\end{proof}

Complete recursions allows us to define $f~(n+1)$ in terms of any or all of the preceding values $f~j$.  This is particularly useful for structures built up from serial pairs \verb!<x,y>!, because of the inequality of natural numbers:
$$
\verb!x <  <x,y>,     y < <x,y>!
$$


\begin{example}  Define \verb!map! as the restriction to the domain of lists of the following function \verb!map:(N -> N) -> N -> N! defined by complete recursion:
\begin{verbatim}
map g <cons,a,p> = <cons,g a,map g p>
map g n = [], otherwise.
\end{verbatim}
\end{example}





\section{boolean}

\begin{note} This section may be disregarded for now.
\end{note}

We define the set of booleans
$$
\ring{B} = \{\verb!false!,\verb!true!\},
$$
where \verb!false=0! and \verb!true=1!.

We define the infix function $\land$ 
as the minimum function on $\ring{N}$, restricted to $\ring{B}$:
$$
x \land y = \min(x,y),
$$
That is, $x\land y$ is true exactly when both $x$ and $y$
are true.

We define the infix function $\lor$ as the maximum
function on $\ring{N}$, restricted to $\ring{B}$:
$$
x\lor y = \max(x,y).
$$
That is, $x\lor y$ is false exactly when both $x$ and $y$ are false.



\chapter{Types}

Foundational systems can be {\it typed} or {\it untyped}.  Zermelo set
theory is an example of an untyped system.  HOL is an example of a typed
system.

In a typed system, every  {\it term} has a {\it type} that describes
what kind of object it is.   It is a descriptive label.  For example, $0$ is a natural number.  We express this by saying that the type of $0$ is the type of natural numbers.  Again, $2$ is a natural number and its type is the type of natural numbers.  Similarly, $1/2$ is a rational number and its type is the type of rational numbers.  The number $\pi = 3.14159\ldots$ is a real number and its type is the type of real numbers.  Similarly, the the type of the base $e=2.71828\ldots$ of the natural logarithm is the type of real numbers.

\bigskip
We give a construction of the set of types in the HOL system.  It is a subset of
$\ring{N}$, depending on a set \verb!typecon!.
Let \verb!tyvar=0!, and \verb!tyapp=1!.
Let \verb!tycon! be a finite set of natural numbers of the form \verb!<s,n>!.
We assume that \verb!tycon! contains the elements
\verb!<"bool",0>! and \verb!<"fun",2>!.  We assume that if \verb!<s,n>=<s,n'>!,
then \verb!n=n'!, for any two elements of \verb!tycon!.

\begin{definition}
We define the set of types of depth \verb!0! to be
the set of order pairs of the form \verb!<tyvar,n>!.  By recursion, we define
the set of types of depth at most \verb!n+1! to be the union of the set
of types of depth at most \verb!n!, and the set of all \verb!<tyapp,s,nlist>!, where for some \verb!n!,
\begin{itemize}
\item \verb!nlist! is a list of length \verb!n!, 
\item each element of \verb!nlist! is a type of depth at most \verb!n!,
\item \verb!<s,n>! is an element of \verb!tycon!.
\end{itemize}
The set of types is the union of the sets of types of depth at most \verb!n! for all \verb!n!.  
\end{definition}

\begin{notation}  We write
$$
\begin{array}{lll}
\hbox{shorthand} & \hbox{full form}\\
\verb!`:A`! &\verb!<tyvar,"A">!\\
\verb!`:B`! &\verb!<tyvar,"B">!\\
\verb!`:bool`!&\verb!<tyapp,"bool",[]>!\\
\verb!`:A->B`!&\verb!<tyapp,"fun",[<tyvar,"A">;<tyvar,"B">]>!\\
\end{array}
$$
\end{notation}
In the notational shorthand, the type information is always preceded by a colon and is enclosed in backquotes.  The ASCII two-stroke arrow \verb!->! is to be understood as a right-associative infix operator.  Thus,
$$
\verb!`:A -> B -> C`! \hbox{ and } \verb!`:A -> (B -> C)`!
$$
both denote the same type as
$$
\scriptsize
\verb!<tyapp,"fun",[<tyvar,"A">;<tyapp,"fun",[<tyvar,"B">;<tyvar,"C">]>]>!
$$
Also, write
$$
\verb!fun_ty a b = <tyapp,"fun",[a;b]>!
$$

\section{basic facts}

Here are some basic facts about types.
\begin{itemize}
\item Every type has exactly one of the following forms:
\verb!<tyvar,_>!, \verb!<tyapp,_>!.
\item Every term in HOL will have a type. (We have not defined terms yet; we will do so soon.)
The type \verb!`:bool`! represents the boolean type.  Eventually, we will prove that every term of this type is equal to true or false.
\item A type of the form \verb!`:A->B`! is a function type.  Any function \verb!`f:A->B`! with domain \verb!`:A`! and range \verb!`:B`! has this type.
\item Types with multiple arrows are the types of curried functions.  A function \verb!`f:A->B->C`! has domain \verb!`:A`! and range \verb!`:B->C`!, which is again a function type.
\item Type variables \verb!<tyvar,_>! represent indeterminate types.   The paradigmatic example is the type of the term \verb!(=)! (equality).  The equals sign takes any two terms of the same type and yields a term of type \verb!`:bool`!.  The two terms that are compared under \verb!(=)! must have the same type, but there are no further restrictions.  We write
$$
\verb!`:A -> A -> bool`!
$$
for the type of \verb!(=)! in curried form.
\end{itemize}



%\section{more facts}

Let \verb!hol_type! be the set of all types.

%Every type has the form \verb!<h,a>! where \verb!h=tyvar! or \verb!h=tyapp!.  Two types \verb!<h,a>!, \verb!<h',a'>! are equal precisely when \verb!h=h'! and \verb!a=a'!.

\begin{lemma}[induction]  Let $X$ is a set of types. Assume that $X$ includes all types of the form \verb!<tyvar,k>!.  Assume that for every element \verb!<s,n>! of \verb!tycon!, and every list \verb!p! of length $n$ all of whose elements belong to $X$, the type \verb!<tyapp,s,p>! belongs to $X$.  Then \verb!X=hol_type!.
\end{lemma}

\begin{proof} If the conclusion if false, the set $\verb!hol_type!\setminus X$ has an element $t$ of least depth $N$.  By assumption it does not have the form \verb!<tyvar,k>!.  So $t$ does not have depth $0$.  So \verb!t=<tyapp,s,p>!   By the definition of types of depth at most $N$, there exists $n$ such that \verb!<s,n>! belongs to \verb!tycon!, \verb!p! has length $n$, and all elements of \verb!p! have depth at most $N-1$.  Since $t$ is a counterexample of least depth, we have that every element of \verb!p! belongs to $X$.  The assumption of the lemma now gives the result.
\end{proof}



\section{type variables}



\begin{definition} We define the function
$$
\verb!tyvars:hol_type!\mapsto \verb!list!
$$
by the restriction to \verb!hol_type! of the following function with domain $\ring{N}$:
\begin{verbatim}
tyvars <tyvar,k> = [<tyvar,k>]
tyvars <tyapp,s,p> = itlist (union o tyvars) p []
tyvars x = [], otherwise.
\end{verbatim}
This function exists uniquely by complete recursion.
\end{definition}

\begin{example}
\begin{verbatim}
tyvars(`:(A->B)->bool`) 
 = itlist (union o tyvars) [`:A->B`;`:bool`] []
 = (union o tyvars) `:A->B` ((union o tyvars)  `:bool` [])
 = (union o tyvars) `:A->B` (union (tyvars `:bool`) [])
 = (union o tyvars) `:A->B` []
 = tyvars `:A->B`
 = itlist (union o tyvars) [`:A`;`B`] []
 = (union o tyvars) `:A` ((union o tyvars) `:B` [])
 = (union o tyvars) `:A` [`:B`]
 = union [`:A`] [`:B`]
 = [`:A`;`:B`]
\end{verbatim}
\end{example}

\section{type substitution}

We define a function
$$
\verb!type_subst!:(\ring{N}\to \verb!hol_type!)\to \verb!hol_type! \to \verb!hol_type!
$$
that replaces each variable with a type according to a given substitution function $\theta:\ring{N}\to \verb!hol_type!$.

%By recursion, we have a function 
%$$f:\ring{N}\times (\ring{N}\to \verb!hol_type!)\to \verb!hol_type! \to \verb!hol_type!$$
%$$
%\begin{array}{lll}
%f~0~\theta~t &=\begin{cases} \theta(k) &\hbox{if } t = \verb!<tyvar,k>!\\ t &\hbox{otherwise}\end{cases}\\
%f~(n+1)~\theta~t &=\begin{cases} \theta(k) &\hbox{if } t = \verb!<tyvar,k>!\\ \verb!<tyapp,s,p'>! &\hbox{if } t = \verb!<tyapp,s,p>!\end{cases}\\
%\end{array}
%$$
%where $p'$ is the list obtained by applying $f(n,\theta,\cdot)$ to each entry of $p'$:
%if $p=[a_0;a_1;\cdots;a_k]$, then
%$$
%p' = [f(n,\theta,a_0);\cdots;f(n,\theta,a_k)].
%$$
%If $ty$ is a type of depth $n$, we set
%%\begin{equation}
%\verb!typ_subst!~\theta~ty = f~n~\theta~ty.
%\end{equation}

\begin{definition}[rev\_assocd]
Define the following function by complete recursion:
\begin{verbatim}
rev_assocd a <cons,<x,y>,t> = if (y=a) then x else rev_assocd a t d.
rev_assocd a n d = d, otherwise
\end{verbatim}
\end{definition}

\begin{definition}[type\_subst]
Define the following function by complete recursion.
\begin{verbatim}
type_subst theta <tyapp,s,p> = <tyapp,s,map (type_subst theta p)>
type_subst theta n = rev_assocd n theta n, otherwise
\end{verbatim}
\end{definition}

\begin{example}
Let $\theta$ be the function
$$
\begin{array}{lll}
\theta(\verb!`:A`!) &=\verb!`:B`!\\
\theta(\verb!`:B`!) &=\verb!`:bool`!\\
\theta(t) &= t,\quad\hbox{otherwise}.
\end{array}
$$
Then
\begin{verbatim}
type_subst theta `:A->B` = `:B->bool`.
\end{verbatim}
\end{example}


%\subsection{recursion analyzed}

%The type substitution function \verb!type_subst! was defined through an auxiliary function $f$.  The type variables function \verb!tyvars! was also defined through a different auxiliary function $f$.  In both cases, the first argument of $f$ is a natural number that was used in the recursive definition of $f$.  Once the recursive definition was complete, we eliminated the first variable by setting it equal to the depth of the type.  The function \verb!typ_subst! satisfies the {\it recursion relation} of Exercise~\ref{ex:type_subst}.

%In the future, we will simply express the definition in the form given by the exercise, rather than giving the auxiliary definition of $f$ directly.  We will say that the definition is given by recursion over the {\it depth}.


\chapter{Terms}

The collective name for mathematical functions, equations, inequalities, formulas, expressions, etc. is {\it term}.  Just about any grammatically correct mathemtical expression is a {\it term}.  A term is a mathematical thing.  This chapter gives a precise definition of the set of all terms in the HOL system.

Since HOL is a typed system, {\it every term has a type}.

\begin{example}
Here are some examples of terms.
\begin{itemize}
\item \verb!`0`!  This is the constant $0$ in the HOL system.  Its type the type of natural numbers.  The backquotes mean that it is a term in the HOL system, as opposed to the number $0\in\ring{N}$ in the metamathematical system.  The notation distinguished between types and terms by marking types with a colon.  Thus, \verb!`:0` = <tyvar,"0">! is a type whose name is the ASCII string \verb!"0"!, but \verb`0` is a term.
%
\item \verb!`(+)`!  This term is the addition function in HOL.  It is a prefix curried function with type \verb!`:num->num->num`!.
%
\item \verb!(=)`!  This term is the equality function in HOL.  It is a prefixed curried function with type \verb!`:A->A->bool`!.  As we will see, more accurately, there is an entire family of equality terms in HOL, obtained by applying type substitutions on the variable \verb!`:A`! in \verb!`:A->A->bool`!
%
\item \verb!`0=0`!  This is an equation in HOL.  Its type is \verb!`:bool`!.  The subterm \verb!`(=)`! has type \verb!`:nat->nat->bool`!.
%
\item \verb!`0`=`0`!  This is a metaequation beween two HOL terms.  The equals sign is not a part of HOL.  It is a metamathemtical equality between two terms.
%
\item \verb!`6=2+4`!  This is a term of type \verb!`:bool`!.
%
\item \verb!`6`=`2+4`!  This is a {\bf false} assertion.  It asserts that \verb!`6`! is the same expresion as \verb!`2+4`!, which is not correct.  
\end{itemize}
\end{example}

\section{definition}

Now we turn to the definition of terms.  First we define {\it raw terms} and then the raw terms that satisfy an additional compatibility condition will be terms. The definition of raw terms depends
on a list $\verb!tmpat!\subset\ring{N}$ of term constant patterns:
$$
\verb!tmpat = [<"=",`:A->A->bool`>;<"@",`:(A->bool)->A`>;...]!
$$
We assume that it contains at least the two indicated elements.
We assume that each element of this set has the
form \verb!<k,ty>!, where $k\in \ring{N}$ and $ty\in\verb!hol_typ!$.
We assume that if \verb!<k,ty>=<k,ty'>!, then \verb!ty=ty'!.

Let \verb!tmvar=0!, \verb!tmcon=1!, \verb!comb=2!, \verb!abs=3!.

\begin{definition} The set of term variables is
$$\verb!var! = \{\verb!<tmvar,k,ty>! \mid k\in\ring{N},\quad ty\in\verb!hol_typ!\}.$$
\end{definition}

\begin{definition} The set of raw terms of depth at most $0$ is
the union of
\begin{itemize}
\item \verb!var!
\item $\{\verb!<tmcon,k,ty>! \mid \exists\theta~ty'.~
  (k,ty')\in \verb!tmpat! \hbox{ and } ty = \verb!type_sub!~\theta ty'\}.$
\end{itemize}
The set of raw terms of depth at most $n+1$ is the union of
\begin{itemize}
\item the set of raw terms of depth at most $n$;
\item $\{\verb!<comb,t1,t2>!\mid t1,t2\hbox{ raw terms of depth at most } n\}$
\item $\{\verb!<abs,v,t>!\mid \ldots\}.$
where the membership condition is that $v$ is a term variable and \verb!t! is a raw term of depth at most $n$.
\end{itemize}
The depth of a raw term is the smallest $n$ for which the
term is a raw term of depth at most $n$.
\end{definition}



\begin{definition} Let \verb!error=0!.  The type of a raw term is defined by recursion over the depth.  It is a function
$$
\verb!hol_type:raw_term -> type UNION {error}!.
$$
%Let \verb!false=0! and \verb!true=1! in the following definition.
The type \verb!hol_type! of a raw term of depth at most $0$ is
$$
\begin{array}{lll}
\verb!<tmvar,k,ty>!&\mapsto \verb!ty!\\
\verb!<tmcon,k,ty>!&\mapsto \verb!ty!
\end{array}
$$
The type of a raw term of depth at most $n+1$ is
$$
\begin{array}{lll}
\verb!<comb,f,x>!&\mapsto 
\begin{cases}
\verb!ty! &\hbox{if } \verb!hol_type f = <"fun",[xty;ty]>)! 
            \hbox{ and } \verb!hol_type x = xty!\\
\verb!error! & \hbox{otherwise}
\end{cases}\\
\verb!<abs,v,b>!&\mapsto
 \begin{cases}
\verb!<"fun",[hol_type v;hol_type b]>)!&\hbox{if } \verb!hol_type b!\ne\verb!error!\\
\verb!error!&\hbox{otherwise}.
\end{cases}
\end{array}
$$
\end{definition}

\begin{definition}
We say that a raw term $t$ is well typed if 
$$
\verb!hol_type t!\ne\verb!error!.
$$  
We define a term to be a raw term that is well-typed.  We define the type of a term $t$ to be \verb!hol_type t!. Write \verb!term! for the set of all terms.
\end{definition}

The set of terms is a subset of $\ring{N}$.  Every term has one of the forms
$$
\verb!<tmvar,_>    <tmcon,_>   <comb,_,_>   <abs,_,_>!
$$
We call these four kinds of terms: variables, constants, combinations, and abstractions.  We discuss each kind of term in turn, starting with combinations.


\subsection{combination}

A combination is a term of the form \verb!<comb,f,x>!.  The well-typing condition is a compatibility condition on the types of $f$ and $x$ for any combination.  It is the requirement that $f$ must have the type of a function
\verb!<"fun",[a;b]>! and that the domain type \verb!a! matches the type of \verb!x!.  The combination \verb!<comb,f,x>! represents the term obtained by applying the function \verb!f! to the element \verb!x! in its domain.

There is a convention shorthand notation for combinations.
$$
\begin{array}{lll}
\hbox{shorthand notation}&\hbox{full form}\\
\verb!`f(x)`! & \verb!<comb,<tmvar,"f",`:A->B`>,<tmvar,"x",`:A`>>!\\
\verb!`f x`! & \verb!<comb,<tmvar,"f",`:A->B`>,<tmvar,"x",`:A`>>!\\
\verb!`x:A`!&\verb!<tmvar,x,`:A`>!\\
\verb!`(+) x y`! & \verb!<comb,<comb,<tmcon,"+",`:nat->nat->nat`>,<tmvar,"x",`:nat`>>,<tmvar,"y",`:nat`>>!\\
\end{array}
$$

The function \verb!`f`! in a combination always takes a single argument \verb!`x`!.  As terms cannot accommodate functions of several variables, they are always put in curried form.

If the raw term is not well-typed, then there is no corresponding term.  For example, if \verb!`f:A->A`! is a term and
\verb!`x:bool`! is another term, there is no term \verb!`f x`!, because the raw type
$$
\verb!<comb,<tyvar,"f",`:A->A`>,<tyvar,"x",`:bool`>>!
$$
is not well-typed.

\subsection{abstraction}

An abstraction is a term of the form \verb!<abs,v,t>!.  It
represents the function that maps \verb!v! to \verb!t!.

For example, \verb!<abs,`x`,`x+1`>! is the function that
takes a term of type \verb!`:nat`! and adds \verb!`1`! to
it.  The type of this abstraction is \verb!`:nat->nat`!.

The HOL system is a descendant of Church's $\lambda$-calculus.
In Church's $\lambda$-calculus, the function $x\mapsto x+1$
is denoted
$$
\lambda x.~x+1.
$$
For ease of typing at a standard keyboard, we represent the Greek lambda as a backslash \verb!\!.
Following Church, we introduce the following abbreviations
for abstractions:
$$
\begin{array}{lll}
\hbox{shorthand notation}&\hbox{standard math}&\hbox{full form}\\
\verb!`\x. x+1`!&x\mapsto x+1&\verb!<"abs",`x`,`x+1`>!\\
\verb!`\x. x+y`!&x\mapsto x+y&\verb!<"abs",`x`,`x+y`>!\\
\verb!`\t. 3`!&t\mapsto 3&\verb!<"abs",`t`,`3`>!\\
\verb!`\t. f(t)`!&t\mapsto f(t)&\verb!<"abs",`t`,`f t`>!\\
\verb!`\x \y. x+y`!&(x,y)\mapsto x+y&\verb!<"abs",`x`,<"abs",`y`,`x+y`>>!\\
\end{array}
$$
In the last example, we have converted the standard math formula into uncurried form.

\subsection{variables}

A term variable functions as an ordinary mathematical variable in the HOL system.  It can stand for an unknown quantity of a given type.
$$
\begin{array}{lll}
\hbox{shorthand notation}&\hbox{full form}\\
\verb!`x:A`!&\verb!<tmvar,"x",`:A`>!\\
\verb!`u:bool`!&\verb!<tmvar,"u",`:bool`>!\\
\verb!`f:A->B`!&\verb!<tmvar,"f",`:A->B`>!\\
\end{array}
$$

\subsection{constants}

Term constants represent terms that have been given a precise fixed mathematical definition, or whose usage has been fixed by the axioms (which we will be describing later).

The HOL system contains a large number of contants.  It
includes mathematical constants such as
$$
\verb!`pi` `e` `0`!
$$
corresponding to the real numbers $\pi$, $e$, and natural number $0$.
It includes logical symbols such as
$$
\verb#`(/\)`  `(\/)` `(==>)`  `(!)` `(?)`#
$$
that are the HOL constants for the logical operations of 
$$
\hbox{\it and},\quad \hbox{\it or},\quad \hbox{\it implies},\quad \hbox{\it for all},\quad \hbox{\it there exists}.$$
It includes mathematical symbols of fixed meanings and standard mathematical functions:
$$
\verb!`sum` `lim` `sqrt` `sin` `cos`!
$$
for 
$$
\sum,\quad \lim,\quad \sqrt{\cdot},\quad \sin,\quad \cos.
$$

This completes our discussion of the four kinds of terms.  We will see that just about any formula, expression, equation, inequality, in just about any math book in the library can be expressed as a HOL term.\footnote{Honestly, there are many books beyond the HOL system, but as we will see, it does remarkable well.}

\section{equality}

The set of terms depends on the set of term constants patterns \verb!tmpat!.  One term pattern is
$$
\verb!<"=",`:A->A->bool`>!
$$
Type substitution on this pattern gives an unlimited number of different constants.
\begin{verbatim}
  `(=):A->A->bool`
  `(=):B->B->bool`
  `(=):bool->bool->bool`
  `(=):(A->C)->(A->C)->bool`
\end{verbatim}
and so forth.  To repeat, there is no single constant \verb!`(=)`!, but various constants denoted by the same symbol and distinguished by their type.
In particular,
\begin{verbatim}
  `((=):A->A->bool) = ((=):B->B->bool)`
\end{verbatim}
is not well-typed and
$$
\verb!`(=):A->A->bool`! \ne \verb!`(=):B->B->bool`!
$$
Also,
$\verb!"A"!\ne \verb!"B"!$ implies that
$$
\verb!`:A`=<tyvar,"A">!\ne\verb!<tyvar,"B">=`:B`!
$$ 
\section{free variables}

In an abstraction \verb!`\x. t`!, the variable \verb!x! is said to be
bound.  In any abstraction
$$
\verb!<abs,x,t>!
$$
all occurrences of the variable \verb!x! (with identical type) in \verb!t! are {\it bound variables}.  Variables that are not bound by any abstraction are free.

Bound variables are similar to {\it dummy variables} in expressions such as 
$$
\begin{array}{lll}
\int_0^3 f(t) dt &= \int_0^3 f(u) du\\
\sum_{i=1}^{10} a_i &= \sum_{j=1}^{10} a_j\\
(\exists x.~x>0)  &\Leftrightarrow (\exists y.~y>0).\\
\end{array}
$$
In fact, later we will see that these dummy variables are just paricular cases of binding variables through abstraction.

Let \verb!var! be the set of term variables; that is, the
set of all terms of the form \verb!<tmvar,_,_>!.
We define a function $\verb!frees:term!\to \verb!P(var)!$
that takes a term and returns all free variables in that term.  For example,
$$
\begin{array}{lll}
\verb!frees `x+y` = {`x`,`y`}!\\
\verb!frees `x+y+x` = {`x`,`y`}!\\
\verb!frees `\x. x` = {}!\\
\verb!frees `\x. x+y` = {`y`}!\\
\verb!frees `x x` = {`x:A->B`,`x:A`}!\\
\verb!frees `(x+0=y)=x` = {`x:nat`,`x:bool`,`y:nat`}!\\
\verb!frees `x+(\x. x+3) 4` = {`x:nat`}!\\
\verb!frees `x+(\t. t+3) 4` = {`x:nat`}!\\
\end{array}
$$

We now give the precise definition of \verb!frees! by
recursion (in terms of an implicit natural number giving the depth of the term):
$$
\verb!frees t! =\begin{cases}
{t} & \hbox{if } \verb!t=<tmvar,_,_>!\\
\emptyset & \hbox{if } \verb!t=<tmcon,_,_>!\\
\verb!(frees f)! \cup \verb!(frees x)!&\hbox{if }\verb!t=<comb,f,x>!\\
\verb!(frees f)!\setminus \{x\}&\hbox{if }\verb!t=<abs,x,f>!
\end{cases}
$$

\begin{example}
\begin{verbatim}
frees `x + (\x. x+3) 4`
 = (frees `(+) x`) UNION (frees `(\x. x+3) 4`)
 = (frees `(+)`) UNION (frees `x`) UNION (frees `(\x. x+3)`) UNION (frees `4`)
 = EMPTYSET UNION {`x`} UNION (frees `(\x. x+3)`) UNION EMPTYSET
 = {`x`} UNION ({`x`} SETMINUS {`x`})
 = {`x`} UNION EMPTYSET
 = {`x`}
\end{verbatim}
\end{example}

\begin{definition} Two terms are $\alpha$-convertible if one can be transformed into another by renaming bound variables.
\end{definition}

We define a function \verb!alphavar! that tests for $\alpha$-convertibility of term variables using a list \verb!env! giving the conversion table. It is recursive over the length of the list.

$$
\begin{array}{lll}
\verb!alphavar env v1 v2! =
\begin{cases}
\verb!true! &\hbox{if } \verb!v1=v2! \hbox{ and } \verb!env=[]!\\
\verb!true! &\hbox{if } \verb!env=<cons,<w1,w2>,env'>, w1=v1, w2=v2!\\
\verb!true! &\hbox{if } \verb!v1! \ne \verb!w1!, \verb!v2! \ne \verb!w2, and alphavar env' v1 v2!\\
\verb!false!&\hbox{otherwise }\\
\end{cases} 
\end{array}
$$

The definition of $\alpha$-convertibility with conversion table is now 
$$\verb!alpha t1 t2 = alpha_env [] t1 t2!
$$
where \verb!alpha_env env t1 t2! is defined by the following conditions:
\begin{itemize}
\item It is false unless \verb!t1! and \verb!t2! are both terms of the same kind (variables, constants, combinations, or abstractions).
\item If both are variables, the value is \verb!alphavar env t1 t2!
\item If both are constants, the terms must equal one another \verb!t1=t2!
\item If both are combinations: \verb!t1=<comb,f1,x1>, t2=<comb,f2,x2>! both parts must recursively be $\alpha$-convertible in the given environment: \verb!alpha_env env f1 f2! and \verb!alpha_env env x1 x2!
\item If both are abstractions: \verb!t1=<abs,x1,f1>, t2=<abs,x2,f>!, then the condition is that the type of $x1$ must equal the type of $x2$ and the bodies of the abstraction must recursively be $\alpha$-convertible in the augmented environment: \verb!alpha_env <cons,<x1,x2>,env> f1 f2!
\end{itemize}

\chapter{Rules of Inference}

\begin{definition}
A sequent is a serial pair \verb!<A,t>!, where $A$ is a list of terms of type \verb!`:bool`! and \verb!`:t`! is a term of type \verb!`:bool`!.
\verb!A! is called the assumption list and \verb!t! is called the conclusion of the sequent.
\end{definition}

A theorem in the HOL system is a sequent obtained from the axioms by repeated applications of the inference rules, and new definitions.  This chapter describes the rules of inference.

The axioms will be introduced much later.  It is possible to go quite far in the HOL system without the axioms.  The axioms will mark the transition from HOL as a system of logic to HOL as a system of mathematics.  For now, we focus on the rules of inference.

A sequent is also written \verb!A |- t!.  If the list of assumptionsis empty, we write it as \verb!|- t!.  The turnstyle symbol \verb!|-! is a keyboard representation of the logical turnstile symbol: $\vdash$.



The rules of inference give us the means to generate theorems.
The rules of inference are given by fiat.  They are not proved correct in any way; justification for them is not provided.  Indeed, how would we prove anything about the inference rules, except by other inference rules?  How would we prove the correctness of logic, except by logic?\footnote{We return to this point later, when we do in fact prove the consistency of the HOL system by means of the meta-logic.}

Nevertheless, if the HOL system is to be used to do traditional mathematics, we should check that the rules of inference conform to our notions of how logic should behave.

Each rule of inference is a function.  The domain of the function varies from rule to rule.  For example, domain may be the set of all terms, or the set of sequents.   The output of the function is a sequent.  Each rule of inference will be presented in stylized form as a {\it fraction}:
$$
\frac{\hbox{INPUT}}{\hbox{OUTPUT}}
$$
In the numerator an element of the domain is listed.  In the denominator the resulting sequent is listed.  

\section{reflection}

The first rule of inference is the reflexive rule of equality.
$$
\verb!REFL!:\quad \frac{a}{\vdash a=a}
$$
The domain is the set of all terms.  The range is the set of sequents:
$$
\verb!REFL:term -> sequent!
$$
\begin{example}
$$
\verb!REFL `0` = <[],`0 = 0`>!
$$
\end{example}

\begin{example}
$$
\verb!REFL `x:A` = <[],`x = x`>!
$$
\end{example}

The rule of reflection is a prime example of a rule of inference that conforms to our expectations.  From long experience, we expect equality to be reflexive; equality would not be deserving of its name if it were not reflexive.  

\section{transitivity}

The second rule of inference is the transitive rule of equality.


$$
\verb!TRANS!:  \frac{\Gamma \vdash a = b;\quad \Delta\vdash b'=c}{\Gamma~\hbox{union}~\Delta \vdash a = c}
$$
where $b$ and $b'$ are $\alpha$-convertible terms.



Pick \verb!error=0!.  Then $\verb!error!\not\in\verb!sequent!$.
The function \verb!TRANS! is a curried function
$$
\verb!TRANS:sequent -> sequent -> sequent! \cup\{\verb!error!\}.
$$
When applying the rule \verb!TRANS s1 s2! to
sequents \verb!s1 = <A1,t1>, s2 = <A2,t2>!,
an error results unless \verb!t1! and \verb!t2! have the
form
$$
\verb!t1 = <comb,<comb,`(=)`,a>,b>,  t2 = <comb,<comb,`(=)`,b'>,c>,!  
$$
where $b$ and $b'$ are $\alpha$-convertible.
When the sequents have this special form, then the result is
the sequent
$$
\verb!<A1 union A2,<comb,<comb,`(=)`,a>,c>>>!
$$

In this rule of inference, the theorems input may have nonempty assumption lists.  If so, the assumptions of both theorems are merged into the output assumption list  without further modification.

\begin{example}\label{ex:trans}
\begin{verbatim}
TRANS (REFL `\x:A. x`) (REFL `\y:A. y`) 
 = TRANS <[],`(\x. x) = (\x. x)`> <[],`(\y. y) = (\y. y)`>
 = <[],`(\x. x) = (\y. y)`>.
\end{verbatim}
\end{example}

\begin{example}
\begin{verbatim}
TRANS (REFL `0`) (REFL `1`) 
 = TRANS <[],`0=0`> <[],`1=1`>
 = error.
\end{verbatim}
\end{example}


By allowing transitivity to match $\alpha$-equivalent terms $b$ and $b'$, we build into the logic our intention of not drawing essential distinctions between $\alpha$-equivalent terms.  Example~\ref{ex:trans} illustrates this by producing a conclusion in which the left and right-hand sides of the equation are $\alpha$-equivalent, but not identical.

As with the reflexive law of equality, the transitive law of equality conforms with our expectation of how equality should behave.  It is natural to make this a rule of inference.  

Equality is not defined.  Its usage is fixed through the rules of inference.  By making equality reflexive and transitive, we bring the usage of the equality symbol in line with our expectations.  Equality is also symmetric.  Symmetry will be proved as a consequence of the rules of inference, rather than made into a separate inference rule.


\section{modus ponens for equality}

There is one more rule for equality \verb!MP_EQ!.  This
is a specialized rule, because it governs equality only
in the situation where the left and right hand sides
of the equation are boolean terms.  When we give an equality of boolean terms, we wish the equality to express that the terms have the same truth-value.  When two boolean terms have the same truth-value, then both should be theorems or neither should be theorems.  


From a given conclusion $p$, we may conclude any other boolean term $q$ of equal truth-value:
%% EQ_MP
$$
\verb!EQ_MP!\quad\frac{\Gamma\vdash p;~~~\Delta \vdash p=q}
{\Gamma~\hbox{union}~\Delta \vdash q}
$$
The function is curried:
$$
\verb!EQ_MP:sequent -> sequent -> sequent!\cup\{\verb!error!\}.
$$
Error results if the conclusion of the second sequent is not an equality of boolean terms.  Error results if the left-hand side of the second conclusion is not identical to the conclusion of the first sequent. The assumption lists are merged without further modification.

An equality between two boolean terms expresses that the two terms have the same truth-value.  Another way of expressing that two boolean terms have the same truth value is with the bi-implication symbol: $\Leftrightarrow$.  Either
$$
\verb!p = q! \quad\hbox{ or }\quad \verb!p! \Leftrightarrow \verb!q!
$$
expresses an identity of booleans.   In these notes, we treat the bi-implication symbol $\Leftrightarrow$ as an alternative notation for the equality of boolean terms.


The name \verb!EQ_MP! is an acronym for {\it equality modus ponens}.  {\it Modus Ponens} is a rule of inference that goes back to antiquity of great significance.  It is so important that in some systems of logic it is the only rule of inference!  The classical rule of modus ponens is the rule
$$
\verb!MP!\quad\frac{\vdash p;~~~\vdash p ==> q}
{\vdash q}
$$
In words, if we have $p$, and also that $p$ implies $q$,
then we get $q$.  This rule will later be obtained as a consequence of the other rules of inference, so we do not introduce it here.  It is mentioned here to show the similarity with equality modus ponens.



\section{make combination}

We have said that a combination \verb!f x = <comb,f,x>! is intended to represent the application of a function \verb!f! to its argument \verb!x!.  The usage of combinations is fixed by the rules of inference.

The next rule of inference declares that equal functions applied to equal inputs produce equal outputs.  This rule fixes the interaction between combinations and equality.  It is called \verb!MK_COMB!  
$$
\verb!MK_COMB!: \frac{\Gamma\vdash f=g;~~~\Delta\vdash a=b}
{\Gamma~\hbox{union}~\Delta\vdash f\hskip0.1em a = g\hskip0.1em b}
$$
The rule of inference is a curried function:
$$
\verb!MK_COMB: sequent -> sequent -> sequent! \cup \{\verb!error!\}.
$$

An error results if the input sequents do not have the
indicated form.  That is, both conclusions must take the form of an equality.  An error results if the raw term $f(a)$ is not well-typed.

\begin{example}
\begin{verbatim} 
MK_COMB <[],`(+) 3 = (+) (2+1)`> <[],`9 = 6 + 3`>
 = <[],`(+) 3 9 = (+) (2+1) (6+3)`>
 = <[],`3 + 9 = (2+1) + (6+3)`>
\end{verbatim}
\end{example}

\begin{example}
\begin{verbatim} 
MK_COMB <[],`\x. x = \y. y`> <[`a = b`],`a = b`>
 = <[`a = b`],`(\x. x) a = (\y. y) b``>
\end{verbatim}
\end{example}

In any proof that involves the replacement of one term by an equal term in a formula, this rule of inference will be involved.


\section{abstraction}

The next two rules of inference govern the usage of abstractions.  The rule of abstraction fixes the interaction between equality of terms and abstractions.  The rule of abstraction declares that equal function bodies give equal functions:
$$
\verb!ABS!\quad\frac{x;~~~\Gamma\vdash a=b}
{\Gamma \vdash \lambda x.\ a~=\lambda x.\ b}
~\hbox{\ (if $x$ is not free in $\Gamma$)}
$$
This rule of inference is a curried function
$$
\verb!ABS: var -> sequent -> sequent!\cup \{\verb!error!\}.
$$
An error results if there is an assumption $a$ in the assumption list $\Gamma$ such that the variable $x$ is free in $a$.
An error results if the conclusion of the sequent does not
have the form of an equality.

\begin{example}
\begin{verbatim}
ABS `x:nat` <[`(+) (1+1) = (+) 2`],`(1+1)+x = 2+x`>
 = <[`(+) (1+1) = (+) 2`],`(\x. (1+1)+x) = (\x. 2+x)`>
\end{verbatim}
\end{example}

\section{beta}

The beta rule is the second rule of inference for abstractions.  It governs the interaction between combinations and abstractions.  An abstraction makes the function and a combination undoes the function.  The beta rule declares that making and breaking the function leaves us where we started. 
In other words, the application of the function $x\mapsto a$ to $x$ gives $a$:
$$
\verb!BETA!\quad \frac{(\lambda x.~a)\, x}
{\vdash (\lambda x.\ a)\, x = a}
$$
This time, the domain of the function is a term:
$$
\verb!BETA: term -> sequent!\cup\{\verb!error!\}.
$$
An error results if the input term does not have the form:
$$
\verb!<comb,<abs,x,a>,x>!
$$
where $x$ is a term variable.

\begin{example}
\begin{verbatim}
BETA `(\t. t+1) t`
 = <[],`(\t. t+1) t = t+1`>
\end{verbatim}
\end{example}

\section{assume}

The next group of inference rules govern the relationship between the assumption list of a sequent and its conclusion.  Without the inference rule \verb!ASSUME!, the only possible assumption list would be the null list.  This rule of inference tells us precisely what we are able to conclude from a given assumption.

%%ASSUME
Assume $p$, then conclude $p$:
$$
\verb!ASSUME!\quad \frac{p\tc bool}
{p \vdash p}
$$
The domain of the function is the set of terms of boolean type.  The range is the set of sequents.  The rule never fails.  There is no requirement for the assumption to be true or even plausible.  
\begin{example}
\begin{verbatim}
ASSUME `false:bool` = <[`false`],`false`>
ASSUME `true:bool` = <[`true`],`true`>
ASSUME `2 < 0` = <[`2 < 0`],`2 < 0`>
ASSUME `2 > 0` = <[`2 > 0`],`2 > 0`>
ASSUME `The_world_is_flat:bool`
 = <[`The_world_is_flat`],`The_world_is_flat`>
\end{verbatim}
\end{example}
At first, one might object to this rule of inference because it can lead to absurd conclusions.  However, the conclusions are absurd only if the assumption is absurd, and there is no way to hide an absurd assumption.  It is there in plain view in the assumption list for all to see.  As with Feyerabend's methodology, {\it anything goes}, as long as you honestly document the assumptions.


\section{antisymmetric deduction}

The previous rule \verb!ASSUME!  is the only rule to create an assumption.  This rule,  antisymmetric deduction, is the only rule to remove an assumption from the list of assumptions in a sequent.  

This rule governs the interaction between the assumption list and bi-implication (equality of boolean terms).
{\it We should be able to conclude $p \Leftrightarrow q$, when we can conclude $q$ assuming $p$ and can also conclude $p$ assume $q$.}

To describe the antisymmetric deduction rule, we need to rely on a function that removes an entry from the assumption list.  There is a recursively defined function
$$
\verb!DROP:list -> !\ring{N} \verb! -> list!.
$$
\verb!DROP p a! removes from a list $p$ every entry that is equal to \verb!a!.
\begin{example}
\begin{verbatim}
DROP [1;2;3] 2 = [1;3]
DROP [1;1;1;2] 1 = [2]
DROP [2;3;4;1;2;1;4] 2 = [3;4;1;1;4]
DROP [] 3 = []
DROP [4;5;6] 1 = [4;5;6]
\end{verbatim}
\end{example}

If the assumption $q$ gives conclusion $p$ and the assumption $p$ gives $q$, then they have the same truth value:
$$
\verb!DEDUCT_ANTI!\quad\frac{\Gamma \vdash p;~~~\Delta\vdash q}
{(\hbox{DROP}~\Gamma~q)~\hbox{union}~(\hbox{DROP}~\Delta~p)
\vdash p=q}
$$
This is a curried function
$$
\verb!DEDUCT_ANTI:sequent -> sequent -> sequent.!
$$
The rule never produces an error.

If the assumption list $\Gamma$ of the first sequent contains assumptions other than $q$, then they are carried into the assumption list of the sequent produced by the rule.  If the assumption list $\Gamma$ does not contain $q$, then nothing is dropped.  Similar comments apply to the assumption list $\Delta$ of the second sequent.

\begin{example}
\begin{verbatim}
DEDUCT_ANTI <[`p`],`q`> <[`q`],`p`>
 = <[],`q=p`>
DEDUCT_ANTI <[`b`],`b`> <[`c`;`b`]>,`a`>
 = <[`b`;`c`],`b=a`>
DEDUCT_ANTI <[],`p`> <[],`q`>
 = <[],`p=q`>
\end{verbatim}
\end{example}
Note the relationship between this final example and the \verb!MP_EQ! rule.  This example shows that any two conclusions have the same truth-value.  The \verb!MP_EQ! rule states that any boolean term with the same truth-value as a conclusion of a theorem can also be concluded.





\section{variable capture}

The final two rules of inference treat variables.  The HOL sytem contains two kinds of variables: type variables such as \verb!`:A`! and term variables such as \verb!`x`!.  There is one inference rule for type variables and one inference rule for term variables.  


We consider type variables first.
When we have a sequent that contains a type variable, this rule of inference allows us to specialize that type variable to any type to obtain a new sequent.  If the sequent contains several type variables, they may all be specialized to any type.

This rule has its restrictions, because of the danger of variable capture.  Variable capture is a particular kind of transformation on sequents that is known to produce inconsistencies in a formal system.  We illustrate with the following example.\footnote{This example uses some elementary arithmetic and existential quantifiers.  These notions will not be introduced into the HOL system until much later.  This is meant as an illustrative example only and may be skipped without affecting the development of the HOL system.}  Consider the following mathematical statement: There exists $f:A\to\ring{N}$ and $x:A$ such that
$$
(f:B->\ring{N})~x < (f:A\to\ring{N})~x.
$$
This statement contains two entirely different variables $x$.  One has type \verb!`:A`! and the other has type \verb!`:B`!.  The statement also contains two entirely different functions with the same name $f$.  One has type \verb!`:A->nat`! and the other has type \verb!`:B->nat`!.  We know that the two $x$s are different and the two $f$s are different because each term has a uniquely determined type.  The statement expresses an arithmetic truth.  It is $\alpha$-equivalent to the statement: 
There exists $g:A\to\ring{N}$ and $y:A$ such that
$$
(f:B->\ring{N})~x < (g:A\to\ring{N})~y.
$$
no matter the value of the function on the left, we could take $g$ to be defined by $g = \lambda y.~f~x + 1$, and then
$$
f~x < f~x + 1,
$$
which is an arithmetic truth.

However, by giving distinct variables the same name, we have created a dangerous situation.  If we make the type substitution on type variables:
$$
\theta(`:B`) = `:A`;\quad \theta(t)=t\hbox{ otherwise}
$$
then the statement becomes:
There exists $f:A\to\ring{N}$ and $x:A$ such that
$$
(f:A->\ring{N})~x < (f:A\to\ring{N})~x.
$$
In this statement the variables $x$ all have the same type and are equal to one another.  Also, the variables $f$ have the same type and are equal to one another.  The statement expresses an arithmetic falsehood; the value of the function cannot be less than itself.

We have thus transformed an arithmetic truth into an arithmetic falsehood by making an unrestricted substitution of type variables.  The problem is precisely that the variable $f:B\to \ring{N}$ is free before the type substitution; it lies within the body of an abstraction; and becomes identical to the binding variable $f:A\to\ring{N}$ of the abstraction.  It is captured.


\section{type substitution}

We consider type variables first.
When we have a sequent that contains a type variable, this rule of inference allows us to specialize that type variable to any type to obtain a new sequent.  If the sequent contains several type variables, they may all be specialized to any type.


Type variable substitution holds provided no variable capture occurs.  If arbitrary types are substituted in parallel for type variables in a sequent, a theorem results.  Type instantiation for sequents is defined through a type instantiation function for terms:
$$
\verb!inst: list -> (tyvar -> typ) -> term UNION {error} -> term UNION {error}!
$$
The first argument \verb!e:list = [<y1,y1'>;<y2,y2'>...]! keeps tabs on the bound variables $y$ in the current scope and what they become $y'$ after variable substitution.  This first argument is needed in order to watch for variable capture.  The second argument $\theta:\verb!tyvar->typ!$ is the function describing the substitutions to be performed on type variables.  The next argument is the term $t$ on which the substitution is to be performed.

Here is a description of how \verb!inst! works.  
\begin{itemize}
\item  If \verb!t=error! then the result of \verb!inst! is also an error.
\item If the term $t$ is a constant \verb!<cons,c,ty>!, then
the output is the constant
$$
\verb!<cons,c,ty_sub theta ty>!
$$
\item If the term $t$ is a combination \verb!<comb,f,x>!, then
recursively call the function \verb!inst! on the two parts:
$$
\verb!<comb,inst e theta f, inst e theta x>!
$$
\item If the term $t$ is a variable \verb!<tmvar,x,ty>!, then
let \verb!ty' = ty_sub theta ty! be its type after substitution
and let \verb!t' = <tmvar,x,ty'>! be the new variable.
If \verb!<t,t'>! is an element of the environment $e$, then
the output is $t'$.  If there is no element of the environment $e$ of the form \verb!<t,_>!, then the output is $t'$.  Otherwise a variable capture has been detected, and the output is \verb!error!.
\item If the variable $t$ is an abstraction \verb!<abs,x,f>!, let
\verb!x' = inst [] theta x! be the new variable, and
\verb!e' = <cons,<x,x'>,e>! the new environment, and 
\verb!f' = inst e' theta f! the new body of the abstraction.
If \verb!f'=error!, then the output is error; otherwise the output
is \verb!<abs,x',f'>!.
\end{itemize}

The rule of inference \verb!INST_TYPE! is curried:
$$
\verb!INST_TYPE: (tyvar->type) -> sequent -> sequent!\cup \verb!{error}!.
$$
Given a type substitution function $\theta$, to apply the rule of inference \verb!INST_TYPE! to a 
sequent \verb!<p,b>!, Let \verb!p'! be the list of terms obtained by applying \verb!inst [] theta! to each entry of \verb!p!, and \verb!b'! the term obtained by applying the same function to \verb!b!.
If \verb!error! is equal to any of the entries of \verb!p'! or to \verb!b!, then the output is \verb!error!; otherwise the result
is the sequent.
$$
\verb!INST_TYPE theta <p,b> = <p',b'>!
$$

A rule of inference for type substitution is essential to the useability of the HOL system.  Otherwise, by proving a theorem for example about \verb!`(=):A->A->bool`! would tell us nothing about \verb!(=):B->B->bool`!  Without type substitution, we would have an unbounded number of variants of each theorem to prove, depending on the variable names.  With a type substitution rule, we can prove one generic theorem with whatever names we please for the type variables, and then instantiate it as needed to any other type variables.

\begin{example}
Let $\theta(\verb!`:A`!) = \verb!`:B`!$ and $\theta(v) = v$,
for $v\ne \verb!`:A`!$.
\begin{verbatim}
INST_TYPE theta <[],`x:A = x:A`>
 = <[],`x:B = x:B`>
\end{verbatim}
\end{example}

\begin{example}
Let $\theta(\verb!`:A`!) = \verb!`:bool`!$ and $\theta(v) = v$,
for $v\ne \verb!`:A`!$.
\begin{verbatim}
INST_TYPE theta <[],`x:A = x:A`>
 = <[],`x:bool = x:bool`>
\end{verbatim}
\end{example}



\section{term instantiation}

The second type of variable is a term variable such as \verb!`x:bool`!.  The rule of inference \verb!INST! replaces each free variable in a term with another given term.  As with type instantiation care must be taken to avoid free variable capture.

Here is an example of capture.  The following statement expresses an arithmetic truth:
There exists \verb!y:nat! such that
$$
\verb!x < y!
$$
If we were to be allowed to instantiate the \verb!x:nat! to \verb!y:nat!, we obtain an arithmetic falsehood:
There exists
\verb!y:nat! such that
$$
\verb!y < y!
$$


Let $\theta=\verb![<y1,t1>;<y2,t2>...]!$ be a list with elements of the form \verb!<y,t>!, where $y$ is a term variable and $t$ is a term.  We assume that the pairs preserve types:
$$
\verb!type_of y = type_of t!
$$
for all \verb!<y,t>! in $\theta$.

Define a recursive function that makes substitutions of terms for variables, using $\theta$.  It is a curried function:
$$
\verb!term_subst:(var -> term) -> term UNION {error} -> term UNION {error}!.
$$
The value \verb!term_subst theta t = t'! is computed as follows
\begin{itemize}
\item Error results if the substitution list $\theta$ does not preserve types.
\item Error results if \verb!t=error!
\item If $t$ is a variable, the value is \verb!t'! if $\theta$ contains an element of the
form \verb!<t,_>! and \verb!<t,t'>! is the first such term.
\item The value is $t$, if $t$ is a constant.
\item The value is defined recursively as
$$
\verb!<comb,term_subst theta f,term_subst theta x>!
$$
if \verb!t=<comb,f,x>! is a combination.
\item Finally, if \verb!t=<abs,x,f>! is an abstraction.  
Let \verb!theta' = <cons,<x,x>,theta>! be the augmented list (bound variables are to be left alone).
The result is an error if
 $\theta$ contains an entry of the form \verb!<y,t>!, where
 $y\ne x$, $y$ is occurs freely in $f$, and $x$ occurs freely in $t$ (because of potential variable capture).  Otherwise, define the result to
be
$$
\verb!<abs,x,term_subst theta' f>!.
$$
\end{itemize}

\verb!INST!  Term variable substitution holds.  If arbitrary terms are substituted in parallel for term variables in a sequent, a sequent results, provided variable capture is avoided.  The function is
curried:
$$
\verb!INST: list -> sequent -> sequent! \cup \verb!{error}!
$$
\verb!INST theta <p,a>! is computed as follows.
Let $p'$ be the list obtained by applying \verb!term_subst theta! to each entry of $p$, and let $a'$ be the term obtained by applying the same function to $a$.  If $a'$ or any entry of $p'$ is \verb!error!, then error results.  Otherwise, the result is the sequent \verb!<p',a'>!.


This completes the description of all the rules of inference in the HOL system.

\chapter{Theorems}

Now that we have a complete list of the rules of inference, we can give a description of the primitive theorems of the HOL system.

\section{state}

We  make the dependence of the system on type constants and term constant patterns explicit.  As we see in a moment are four lists that influence the construction of types, terms, and theorems. The state of the HOL system depends on four lists, which we package together as a single list $s$ with four entries:
\begin{equation}\label{eqn:state}
\verb!s = [tycon;tmpat;axiom_list;def_list].!
\end{equation}
We let \verb!state! be the set of all lists of length four such that every entry is itself a list.
We have a function
$$
\verb!type_from:state -> !\ring{N}
$$
depending only on the first entry of the state,
that constructs the types from the list of type constants.
\begin{example}
The set of types for the primitive HOL system is
\begin{verbatim}
type = type_from [primtycon;[];[];[]]
primtycon = [<"bool",0>;<"ind",0>]
\end{verbatim}
\end{example}

The set of terms depends on the set of type constants and on the set of term constant patterns:
$$
\verb!term_from:state -> !\ring{N}.
$$
\begin{example}
The set of terms for the primite HOL system is
$$
\verb!term = term_from [primtycon;primtmpat;[];[]]!
$$
\end{example}



\section{primitive theorems}

Given these four lists, we can construct types, terms, and theorems as outlined.  If these lists change, we get different sets of types, terms, and theorems.

\begin{definition}[{\tt thm from}]
We define a function
$$
\verb!thm_from: state -> P(sequent)!
$$
that constructs a set of sequents from the state.
The recursive definition of
$$
\verb!thm_from [tycon; tmpat; axiom_list; def_list]!
$$
is as follows.  The set of theorems of depth at most $0$ is the set of axioms and definitions:
 $$\verb!setify (def_list union axiom_list)!.$$  
A theorem of depth at most $n+1$ can be any theorem of depth at most $n$,  or any sequent that can be obtained as the error-free output of any of the ten rules of inference, where the input sequents (for the rules of inference that require one or more sequents) are theorems of depth at most $n$.  The depth of a theorem is the smallest $n$ such that it is a theorem of depth at most $n$.
\end{definition}

\begin{definition}[primitive theorems]
The set of {\it primitive theorems} is the set of theorems associated with the following state lists.  The list of type constants is 
$$
\verb!primtycon!
$$
The list of term constant patterns is
$$
\verb!primtmpat = [<"=",`:A->A->bool`>;<"@",`:(A->bool)->A`>]!
$$
For primitive theorems, we take the list of axioms to be empty: \verb!axiom_list=[]!.  We also take the definition list to be empty: \verb!def_list=[]!.
\end{definition}


\begin{example}  There are no primitive theorems of depth $0$.
Example of primitive theorems of depth $1$ are
\begin{verbatim}
REF `x:A` = <[],`x:A = x:A`>
ASSUME `p:bool` = <[`p:bool`],`p:bool`>
\end{verbatim}
\end{example}



\section{Definitions}

The primitive HOL system may be extended with definitions.  There are two kinds of definitions: definitions that define new types and definitions that define new terms.

\subsection{type definitions}

It is possible to extend the primitive HOL system by defining new types.  The set of all elements of a given new type is required to be in bijection with a non-empty subset of an existing type.


A type definition is a uncurried function
$$
\verb!TY_DEF:state ->! \ring{N}^3\verb! -> sequent -> state!
$$
that modifies the state of the HOL system.

As with the rules of inference, there are various inputs that trigger an error.  In this case, we bail out by returning the same four-tuple of lists that was input.  In other words, we abandon our edits and return to the original state.

We compute
\begin{verbatim}
TY_DEF [tycon;tmpat;axiom_list;def_list] (s,rep,abs) <A,q> 
 = [tycon';tmpat';axiom_list';def_list']
\end{verbatim}
as follows.  First, we mention some requirements; if any of the following conditions fails to hold, an error is triggered and the state is left unchanged:
\begin{itemize}
\item There is no entry of the form \verb!<s,_>! in \verb!tycon!.
\item There is no entry of the form \verb!<rep,_>! or \verb!<abs,_>! in \verb!tmpat!.
\item $\verb!A = []!$.
\item $q$ is a combination \verb!<comb,P,t>!.
\item $P$ contains no free variables.
\end{itemize}  
Let \verb!tyv! be the list of all type variables in $P$, listed without duplication.  Let $n$ be the length of that list.  

One new type is created:
$$
\verb!tycon' = <cons,<s,n>,tycon>!
$$
We have the type constant `:s`
$$
\begin{array}{lll}
\verb!sty = <tycon,s,tyv>!\in \verb!type_from tycon'!\\
\verb!rty = type_of t!\in \verb!type_from tycon'!\\
\end{array}
$$
Two new constant patterns are created (functions giving a correspondence in both directions between the old type and the new type):
\begin{verbatim}
tmpat' = <cons,abspat,<cons,reppat,tmpat>>
abspat = <abs,fun_ty rty sty>
reppat = <rep,fun_ty sty rty>
\end{verbatim}
We have term constants \verb!`abs`! and \verb!`rep`! given in expanded form as
$$
\begin{array}{lll}
\verb!<tmcon,abs,fun_ty rty sty>!\in \verb!term_from tycon' tmpat'!\\
\verb!<tmcon,rep,fun_ty sty rty>!\in \verb!term_from tycon' tmpat'!\\
\end{array}
$$
The axiom list remains unchanged:
$$
\verb!axiom_list' = axiom_list!
$$
Two new sequents are added (concluding that the functions giving the correspondence between the old type and the new type define a bijection):
$$
\verb!def_list' = <cons,abs_rep,<cons,rep_abs,def_list>>!
$$
The two sequents are given in the following stylized form:
$$
\verb!abs_rep, rep_abs!\quad \frac{\vdash P~t}
{\begin{array}{rll}\vdash& abs(rep~a) = a\\ \vdash& P~r = (rep(abs~r) = r)\end{array}}
$$
Here \verb!abs! and \verb!rep! are the new term constants given above, and $a$ and $r$ are type variables whose types are determined by the those of the constants.

We will see many examples of new type definitions in this book.





\subsection{term definitions}

It is possible to extend the HOL system with new term definitions.  This
section explains how.  In stylized form it is given as follows:
$$
\verb!DEF!\quad \frac{c~=~t}
{\vdash~c~=~t}
$$
It is a curried function
$$
\verb!DEF:state -> term -> state!
$$
that modifies the four lists (\ref{eqn:state}) giving the state of the HOL system.

As with the rules of inference, there are various inputs that trigger an
error.  In this case, we bail out by returning the same four-tuple of lists that was input.  In other words, we abandon our edits and return to the original state.

We compute
\begin{verbatim}
DEF [tycon;tmpat;axiom_list;def_list]  q 
 = [tycon';tmpat';axiom_list';def_list']
\end{verbatim}
as follows.  First, we mention some requirements; if any of the following conditions fails to hold, an error is triggered and the state is left unchanged:
\begin{itemize}
\item $q$ is a boolean term of the form $c=t$.
\item $c$ is a term variable \verb!<tmvar,c0,ty>!.
\item There is no constant pattern of the form \verb!<c0,_>! in \verb!tmpat!.
\item $t$ is a term that contains no free variables.
\item Every type variable in $t$ is contained is a type variables in $ty$.
\end{itemize}  
The set of type constants remains unchanged: \verb!tycon'=tycon!.
There is one new term constant pattern: 
$$
\verb!tmpat' = <cons,<c0,ty>,tmpat>!
$$
There are no new axoms: \verb!axiom_list'=axiom_list!.
There is one new sequent:
\begin{verbatim}
def_list' = <cons,newdef,def_list>
\end{verbatim}
where the new sequent has no assumptions and a conclusion in the the same form $c=t$ as $q$, except that now $c$ is a term constant \verb!<tmcon,c0,ty>! matching the new pattern.

\begin{example}
\begin{verbatim}
DEF [a;b;c;d] `two = 1+1`
 = [a; <cons,<"two",`:nat`>,b>; c; <cons,<[],`two = 1+1`>,d>]
\end{verbatim}
\end{example}


Nothing stops us from making outrageous definitions
\begin{verbatim}
DEF [tycon;tmpat;axiom_list;def_list] `the_Riemann_hypothesis = (0=0)` 
 = [tycon;tmpat';axiom_list;def_list']
tmpat' = <cons,<"the_Riemann_hypothesis",`:bool`>,tmpat>
def_list' = <cons,<[],`the_Riemann_hypothesis = (0=0)`>,def_list>
\end{verbatim}
With this definition, the theorem \verb!<[],`the_Riemann_hypothesis`>! is easily derived. However, although anything goes with definitions, all definitions are permanently recorded in the state of the HOL system.



\section{Axioms}

It is possible to extend the HOL system with new axioms.  A new axiom changes the state:

$$
\verb!AXIOM!\quad \frac{p\tc bool}
{\vdash~p}
$$
It is a curried function
$$
\verb!DEF:state -> {p : boolean term} -> state!
$$
that modifies the state of the HOL system.  In fact, it only modifies the axiom list by adding a new sequent with empty assumption list and conclusion $p\tc bool$:
\begin{verbatim}
AXIOM [tycon;tmpat;axiom_list;def_list] p 
 = [tycon;tmpat;axiom_list';def_list]
axiom_list' = <cons,<[],p>,axiom_list>
\end{verbatim}



This section states the axioms that will be used in this book. These axioms will be discussed in depth later.  Here we list them for future refernce.  There are only three mathematical axioms.
$$\begin{array}{lll}
\hbox{Axiom of Extensionality:} &\quad\forall f.\hskip1em(\lambda x.\, f\, x) = f.\\
\hbox{Axiom of Infinity:} &\quad\exists f\tc ind\to ind.~~(\op{ONE\_ONE}\,f) \land \neg(\op{ONTO}\, f).\\
\hbox{Axiom of Choice:}&\quad  
\forall P\,x.\hskip1em P x \Rightarrow  P(\varepsilon P).\\
\end{array}
$$
Extensionality asserts that every function is determined by its input-output relation. Dedekind's axiom of infinity asserts the existence of a function that is one-to-one but not onto.  The Hilbert choice operator $\varepsilon$ applied to a predicate $P$ chooses a term that satisfies the predicate, provided the
predicate is satisfiable.


\section{extensions}

Starting from the primitive HOL system we can make a finite number of extensions.  Each extension adds an axiom, a new type definition, or a new term definition to the previous extension.  In the chapters that follow many new definitions and types will be added, enlarging the state of the system as we develop more and more logic and mathematics.


