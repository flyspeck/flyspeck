(* ========================================================================== *)
(* FLYSPECK - BOOK FORMALIZATION                                              *)
(*                                                                            *)
(* HOL Light general library                                                  *)
(* Author: Thomas C. Hales                                                    *)
(* Date: 2013-09-11                                                           *)
(* ========================================================================== *)

(* save theorems out to disk and reload.

   N.B. If this file is reloaded, then the reloaded file lacks the
   ability to carry out theorem imports. The mk_local_inconsistency function
   occurs in a local context that is wiped out by a reload.
 *)

needs "general/theorem_digest.hl";;
needs "general/theorem_nonlinear_digest.hl";;
needs "general/prove_by_refinement.hl";;

let _ = if Str.string_match (Str.regexp "Ocaml 4.") (ocaml_version()) 0 then 
  needs "general/update_database_400.ml"
else
  needs "general/update_database_310.ml";;

(* #load "str.cma";; *)

module Serialization = struct


(* state manager should reset new_type_abbrev and the_implicit_types. *)

(* string comparison function *)

module  String_compare : Set.OrderedType with type t = string = struct
  type t = string;;
  let  compare (t1:string) (t2:string) = Pervasives.compare (t1) (t2);;
end;;

module St = Set.Make(String_compare);;

(* remove duplicate entrie from a list *)

let rec nub = function (* from lpproc.ml *)
  | [] -> []
  | x::xs -> x::filter ((<>) x) (nub xs);;

(* join strings with given separator *)

let join_ sep = 
  function 
    | [] -> ""
    | x::xs as u -> end_itlist (fun s t -> s^sep^t) u;;

let join_semi = join_ ";";;

let join_space = join_ " ";;

(* ********************************************************************** *)
(* Types and terms are put in canonical form by renaming variables.  *)
(* ********************************************************************** *)

(* type variables are renamed A0, A1 *)

let mk_vartypen n = map (fun i -> mk_vartype ("A"^(string_of_int i))) (0-- (n-1));;

let canonize_tyl tyl =
  let tys = map tyvars tyl in
  let tys' = nub (List.flatten tys) in
  let ntys = mk_vartypen (List.length tys') in
    zip ntys tys';;

let canonize_varty_in_thm th = 
  let (a1,a2) = dest_thm th in
  let a = a2::a1 in
  let tyl = List.flatten (map type_vars_in_term a) in
  let ctyl = canonize_tyl tyl in
    INST_TYPE ctyl th;;

(* free variables in a term are renamed x0, x1, x2, ... *)

let canonize_frees_in_thm th = 
  let vl = thm_frees th in
  let n = List.length vl in
  let sl = map (fun i -> ("x"^(string_of_int i))) (0-- (n-1)) in
  let xl = map (fun (s,v) -> mk_var (s,snd(dest_var v))) (zip sl vl) in
    INST (zip xl vl) th;;

let mk_b_var base (i, v) = 
  let (_,ty) = dest_var v in
  let b = mk_var(base^(string_of_int i),ty) in
    b;;

(* bound variables in a term are renamed b0, b1, b2, ... *)

let rec canonize_bound base (i,t) = 
  match t with 
    | Abs(v,bod) -> 
	let (j,b') = canonize_bound base (i,bod) in
	  (j+1,alpha (mk_b_var base (j,v)) (mk_abs(v,b')))
    | Comb(u,v) ->
	let (j,u') = canonize_bound base (i,u) in
	let (j',v') = canonize_bound base (j,v) in
	  if (i=j') then (i,t) else (j',mk_comb (u',v'))
    | _ -> (i,t);;

let rec DISCH_ALL_ALT th = 
  match hyp th with
      [] -> th
    | x::xs -> DISCH_ALL_ALT (DISCH x th);;

(* rename bound variables in theorem, 
   taking care if b* is already a bound variable *)

let canonize_thm th = 
  let th1 = canonize_varty_in_thm th in
  let th2 = canonize_frees_in_thm th1 in
  let n = List.length (hyp th2) in
  let th3 = DISCH_ALL_ALT th2 in
  let vl =  filter (fun v -> v.[0]='b') (map (fst o dest_var) (variables (concl th3))) in
  let split = Str.split (Str.regexp "[^b]+") in
  let bl = map (String.length o hd o split) vl in
  let m = List.fold_right max bl 0 in
  let base = String.make (m+1) 'b' in
  let t0 = if not("b"=base) then snd (canonize_bound base (0,concl th3)) else concl th3 in
  let (_,t) = canonize_bound "b" (0,t0) in
  let eq = ALPHA (concl th3) t in
  let th4 =   EQ_MP eq th3 in
    funpow n UNDISCH th4;;

(* ********************************************************************** *)
(* extract type constants and term constants from types and terms *)
(* ********************************************************************** *)

let rec get_type_constants_rec acc ty = match ty with
    | Tyvar s -> []
    | Tyapp (s,tyl) -> 
	let gyl = List.flatten (map (get_type_constants_rec []) tyl) in
	  s :: gyl @ acc;;

let get_type_constants ty = nub (get_type_constants_rec [] ty);;

let rec type_constants_in_term_rec tm acc =  
  match tm with
    | Abs(x,y) -> ["fun"] @ type_constants_in_term_rec x [] @ type_constants_in_term_rec y [] @ acc
    | Comb(x,y) -> type_constants_in_term_rec x [] @ type_constants_in_term_rec y [] @ acc
    | Var (_,ty) -> get_type_constants ty @ acc
    | Const(s,ty) -> get_type_constants ty @ acc;;

let type_constants_in_term tm = nub(type_constants_in_term_rec tm []);;

let type_constants_in_thm th = 
    let a1,a2 = dest_thm th in
    let al = map type_constants_in_term (a2::a1) in
    nub (List.flatten al);;
    
let rec get_term_constants_rec acc tm = match tm with
  | Var(s,ty) -> acc
    | Const(s,ty) -> s::acc
    | Comb(u,v) -> let su = get_term_constants_rec [] u in
      let sv = get_term_constants_rec [] v in
	su @ sv @ acc
    | Abs(x,y) -> let su = get_term_constants_rec [] x in
      let sv = get_term_constants_rec [] y in
	su @ sv @ acc;;

let get_term_constants tm = nub (get_term_constants_rec [] tm);;

let get_term_constants_in_thm th = 
  let a1,a2 = dest_thm th in
  let al = map get_term_constants (a2::a1) in
    nub (List.flatten al);;

(* These are types in HOL Light that don't get properly recorded elsewhere *)

let table_stray_typ = 
  [("hreal","mk_hreal","dest_hreal"), hreal_tybij;
    ("real","mk_real","dest_real") , real_tybij;
   ("recspace","_mk_rec","_dest_rec"),  recspace_tydef;
  ("num","mk_num","dest_num"), num_tydef;
 ("nadd","mk_nadd","dest_nadd"), (nadd_abs,nadd_rep)
  ];;

let process_inductive_term = 
  let reg = Str.split (Str.regexp "[ |=]+") in
  let ignores = ["A";"B";"bool"] in
    fun tint ->
      let rs =  (tl o reg) (fst tint) in
      let rs1 = subtract rs ignores  in
      let (u,v) = snd tint in
      let zz2 = map (fun t -> (t, (CONJ u v))) rs1 in
    zz2;;

(*
let table_inductive_term = map process_inductive_term !the_inductive_types;;
*)

let process_table_typed_term tl =   
  let a1 = (fun (_,b,_),(u,v) -> (b,CONJ u v)) tl in
  let a2 = (fun (_,_,c),(u,v) -> (c,CONJ u v)) tl in
    [a1 ;a2];;

(*
let table_typed_term = 
  map process_inductive_term !the_inductive_types @
    map process_table_typed_term !the_type_definitions @ 
    map process_table_typed_term table_stray_typ;;
*)

let process_table_def_term = 
  let name d = let 
      (c,_) = dest_const (lhs (concl d)) in c in
    fun d -> (name d,d);;

(* ********************************************************************** *)
(* marker for deserialized theorems.
All theorems that are imported are marked with an assumption
  `deserialization:bool` that shows that the theorem was imported.
 Eventually, `deserialization` can be added as an axiom, to allow all 
 legitimate imports.
 *)
(* ********************************************************************** *)

let bool_ty = Hol.bool_ty;;

let deserial = "deserialization";;

let deserial_var = mk_var(deserial,bool_ty);;

let is_deserial t = is_const t && ( dest_const t = (deserial,bool_ty));;

(*
is_var `deserialization` || failwith "deserialization variable already in use";;
*)

let is_deserial_axiom th = 
  hyp th = [] && is_deserial (concl th);;

(* ********************************************************************** *)
(* serializing and digesting types and terms 
  By serialization, we mean faithfully mapping types, terms, 
   and theorems to strings.
  The simple digest of a theorem is the md5 hash of the string of the theorem
    in canonical form.
*)
(* ********************************************************************** *)

let buf = Buffer.create 8000;;

let addb = Buffer.add_string buf;;

let rec addbs f y = match y with 
    [] -> ()
  | x::xs ->  (f x); if not(xs=[]) then addb ";"; addbs f xs ;;

(* convert a types, terms, and thms to a string *)

let rec serialize_typb ty = 
  match ty with
    | Tyvar s ->  addb "Tyvar \""; addb s; addb "\""
    | Tyapp (s,tyl) -> addb "Tyapp(\""; addb s; addb "\",["; 
	addbs serialize_typb tyl; addb "])";;


let rec serialize_termb = function
    | Var(s,ty) ->  addb "Var(\""; addb s; addb "\",";  (serialize_typb ty); addb ")" 
    | Const(s,ty) -> addb "Const(\""; addb s; addb "\",";  (serialize_typb ty); addb ")" 
    | Comb(u,v) -> addb "Comb("; (serialize_termb u); addb ","; (serialize_termb v); addb ")"  
    | Abs(x,y) -> addb "Abs("; (serialize_termb x); addb ",";  (serialize_termb y); addb ")"  ;;

let serialize_thm th = 
  let _ = Buffer.reset buf in
  let (h,t) = dest_thm th in
  let h' = filter (not o is_deserial) h in
  let _ = addb "["; addbs serialize_termb h'; addb "] |- "; serialize_termb t in
    Buffer.contents buf;;

let simple_digest_thm th = 
  (* let _ = (canonize_thm th = th)  || (report (string_of_thm1 th); failwith "smple") in *)
    Digest.to_hex (Digest.string (serialize_thm ( th)));;

simple_digest_thm (canonize_thm REAL_LE_TRANS) =  "0a27c9abba9dc352b772ca75bf62b7c5" ||
  failwith "simple_digest_thm error";;

let example1 = 
  let ETA2 = (canonize_thm ETA_AX) in
    (ETA2,serialize_thm ETA2,simple_digest_thm ETA2);; (* "65bb2b4953a56dda9bee095ce9660e56" *)


(* ********************************************************************** *)
(* history of theorems *)
(*
A theorem depends on an entire recursive history of 
definitions of constants and types.

For an import of a theorem to be justified, the entire history
of the theorem in the exporting session 
must have an identical history in the importing session.

The following procedures compute the entire histories for  
types, terms, and theorems.

We then form a full digest of a theorem that takes the entire history
into account.

*)
(* ********************************************************************** *)

(* process two global lists of types: 
   the_inductive_types and the_type_definitions *)

let get_simple_table_typ =
  let split = Str.split (Str.regexp " +") in
  let len_inductive_types = ref 0 in
  let len_type_definitions = ref 0 in 
  let current_canon = Hashtbl.create 50 in
  let _ = Hashtbl.clear current_canon in
  let p_can (s,t) = let th = canonize_thm t in
    (s,(simple_digest_thm th,th))  in
  let p_ind = (fun (s,(u,v)) -> hd(split s), (CONJ u v)) in
  let p_def = (fun (a,_,_),(u,v) -> (a, (CONJ u v))) in 
  let add_ind () = 
    let _ = 
    funpow (List.length !the_inductive_types - !len_inductive_types)
      (function [] -> [] | x::xs -> 
	 let (ty,th) = (p_can o p_ind) x in
	 let _ = Hashtbl.add current_canon ty th in
	   xs) !the_inductive_types in
    let _ = len_inductive_types:= List.length !the_inductive_types in
      () in
  let add_def () = 
    let _ = funpow (List.length !the_type_definitions - !len_type_definitions)
      (function [] -> [] | x::xs ->
	 let (ty,th) = (p_can o p_def) x in
	 let _ = Hashtbl.add current_canon ty th in
	   xs) !the_type_definitions in
    let _ = len_type_definitions:= List.length !the_type_definitions in
      () in
  let _ = 
    let xs = map (p_can o p_def) table_stray_typ in
      map (fun (ty,th) -> Hashtbl.add current_canon ty th) xs in
    fun sty -> try Hashtbl.find current_canon sty with Not_found ->
      let _ = add_ind(); add_def() in
	try Hashtbl.find current_canon sty with Not_found -> failwith ("Missing type: "^sty);;

let get_simple_table_term =
  let len_inductive_types = ref 0 in
  let len_type_definitions = ref 0 in 
  let len_definitions = ref 0 in
  let current_canon = Hashtbl.create 2000 in
  let _ = Hashtbl.clear current_canon in
  let add (ty,th) = Hashtbl.add current_canon ty th in
  let p_can (s,t) = let th = canonize_thm t in
    (s,(simple_digest_thm th,th))  in
  let add_ind () = 
    let _ = 
    funpow (List.length !the_inductive_types - !len_inductive_types)
      (function [] -> [] | x::xs -> 
	 let _ = map (add o p_can) (process_inductive_term x) in
	   xs) !the_inductive_types in
    let _ = len_inductive_types:= List.length !the_inductive_types in
      () in
  let add_table_typed_term ls k = 
    let _ = funpow k
      (function [] -> [] | x::xs ->
	 let _ = map (add o p_can) (process_table_typed_term x) in
	   xs) ls in
      () in
  let add_typed_term () = 
    let k = List.length !the_type_definitions - !len_type_definitions in
    let _ = add_table_typed_term !the_type_definitions k in
    let _ = if (k>0) then len_type_definitions:= List.length !the_type_definitions in
      () in
  let add_table_term () = 
    let hd = Hol.definitions() in
    let n = List.length hd in
    let k = n - !len_definitions in
    let _ = 
      funpow k
	(function [] -> [] | x::xs -> 
	   let _ = (add o p_can o process_table_def_term) x in
	   xs) hd in
    let _ = len_definitions := n in 
      () in
  let _ = add_table_typed_term table_stray_typ (List.length table_stray_typ) in
  let _ = add_table_term(); add_ind(); add_typed_term();  in
    fun sty -> try Hashtbl.find current_canon sty with Not_found ->
      let _ = add_table_term(); add_ind(); add_typed_term();  in
	try Hashtbl.find current_canon sty with Not_found -> failwith ("Missing term: "^sty);;


let assocs s xl = 
  try assoc s xl with Failure _ -> failwith s;;

let hash2 = Hashtbl.create 2000;;

Hashtbl.clear hash2;;

let rec get_history_thm_rec2 ty_ignore tm_ignore (d,th)  =
  try Hashtbl.find hash2 d with  | Not_found ->
    let sort_uniq = uniq o (sort (fun a b -> fst a < fst b)) in
    let ty = subtract (type_constants_in_thm th) ty_ignore in
    let tm = subtract (get_term_constants_in_thm th) tm_ignore in
(*    let t1 = map (fun t -> assocs t simple_table_typ) ty in *)
    let t1 = map get_simple_table_typ ty in
    let t2 = try map get_simple_table_term tm with 
	Failure s -> (report (string_of_thm th); failwith s ) in 
    let t3 = filter (fun t -> not (d = fst t)) (t1 @ t2) in
    let ts = sort_uniq (t3) in
    let try_history t1 = try get_history_thm_rec2 ty_ignore tm_ignore t1 with 
	Failure s -> (report (string_of_thm (snd t1)); failwith s) in
    let f = List.flatten (map try_history ts) in
    let f1 = (d,th) :: ts @ f in
    let f' = uniq  (sort (fun a b -> fst a < fst b) f1) in
    let _ = Hashtbl.add hash2 d f' in
      f';;

(*
The history ignores types that are already in the kernel, because
they are inalterable.  The history also ignores constants in the kernel
for the same reason.

The history ignores the deserialization axiom and deserialization constant
that are created in this module.  This permits the incremental use of
of this module: a session using the deserialization axiom can import/export in
the same way that a session that does not use the deserialization axiom.
*)

let get_history_thm1 = 
  let ty_ignore = ["bool";"fun";"ind"] in
  let tm_ignore = ["=";"fun";"@";deserial] in
  let mk th = let c = canonize_thm th in (simple_digest_thm c),c in
  let sort_uniq = uniq o (sort (fun a b -> fst a < fst b)) in
  let axiom_reduced = filter (fun t -> not(is_deserial_axiom t)  ) (axioms()) in
  let d_axiom = map mk (axiom_reduced) in
  let ax_history = sort_uniq (List.flatten 
				(map (get_history_thm_rec2 ty_ignore tm_ignore) d_axiom)) in
    fun th ->
      sort_uniq (ax_history @ get_history_thm_rec2 ty_ignore tm_ignore (mk th));;

(* ********************************************************************** *)
(* the full digest takes the entire history of the theorem into account,
   it puts the history in sorted order then takes the hash *)
(* ********************************************************************** *)

let full_digest_thm th = 
  let history =  (get_history_thm1) th in
  let h2 =  (map fst) history in
  let h4 =  (join_space  o nub o  (sort (<))) h2 in
    Digest.to_hex (Digest.string h4);;

full_digest_thm ETA_AX =  "63e9b5b016229a78bb720593f38b0b3e" 
      || failwith "full_digest_thm error";;

(* TESTS:
time full_digest_thm Pack2.PACKING;; (* "ba442e7e51b8bd5ee6903a114aa5eb8d" *)
time full_digest_thm Pack2.PACKING;; (* "ba442e7e51b8bd5ee6903a114aa5eb8d" *)
time full_digest_thm Tskajxy_034.TSKAJXY_034;; (* "04971c3d90ed713737c92af7244efeb1" *)
time (simple_digest_thm o  canonize_thm) Tskajxy_034.TSKAJXY_034;; (* "7313b1f9b0ff0b1a746544267fbd823e" *)
time full_digest_thm ETA_AX;; (* "63e9b5b016229a78bb720593f38b0b3e" *)
time full_digest_thm REAL_LE_TRANS;; (* 9e9bbb6556672ce154be3c9e28380e33 *)
time full_digest_thm Merge_ineq.example1;; (* "6288c02e24ab8dc0fd49b4ee2c1fdc33" *)
mem "6288c02e24ab8dc0fd49b4ee2c1fdc33" Theorem_digest.digest_list_extern;;
full_digest_thm Qzyzmjc.QZYZMJC;; (* "ce0814956a89ca0159839762dfd44b7d" *)
mem "ce0814956a89ca0159839762dfd44b7d" Theorem_digest.digest_list_extern;;
*)

let digest_thms some_thml = 
  let digests =  map 
    (fun t -> try full_digest_thm t;
     with 
       | Failure s -> (report ("cannot digest: "^(string_of_thm t)); "") 
       | Not_found -> (report ("cannot digest, not found: "^(string_of_thm t)); "")) 
    some_thml in
    filter (fun s -> not (s = "")) digests;;
  
(*
let digest_list = 
  let _ = update_database() in
    time digest_thms (map snd (!theorems));; (* 729 secs, 293 secs. 215 secs. 191 secs. *)

subtract digest_list Theorem_digest.digest_list_extern;;
subtract Theorem_digest.digest_list_extern digest_list ;;

*)


(* ********************************************************************** *)
(* writing the digest strings out to file *)
(* ********************************************************************** *)

let save_stringarray filename xs head sep tail = 
  let wrap_str s = "\""^s^"\"" in
  let out = Pervasives.output_string in
  let oc = open_out filename in
  let _ = out oc head in
  let _ = for i=0 to length xs -1 do      out oc (wrap_str(List.nth xs i) ^ sep);  done in
  let _ = out oc tail in
  let _ = close_out oc in
    ();;

let digest_file = Filename.temp_file "digest" ".hl";; 

let save_all digest_list = 
  let head = "module Theorem_digest = struct\n\n let digest_list_extern = [\n" in
  let sep = ";\n" in
  let tail = "];;\n\nend;;" in
    save_stringarray digest_file digest_list head sep tail;;

let load_digest_file() = 
  needs digest_file;;

(*
save_all();;
load_digest_file();;
digest_list = Theorem_digest.digest_list_extern;;
List.length digest_list;;
List.length Theorem_digest.digest_list_extern;;
let dd1 = subtract Theorem_digest.digest_list_extern digest_list;;
map (fun t -> assoc t hashes2) dd1;;
*)

let thm_list = ref [];;

let add_thm th = 
  let _ = thm_list := th :: !thm_list in
    ();;

(* Export all theorems in the HOL Light database *)

let save_all_theorems() = 
  let _ = update_database() in
  let tt = (map snd !theorems) @ !thm_list in
  let tt2 = uniq (sort (<) 
		(Theorem_digest.digest_list_extern @ digest_thms tt)) in
  let _ =   save_all tt2 in
    ();;


let set_of_string sl = 
  let acc = St.empty in
    List.fold_right St.add sl acc;;

(* ********************************************************************** *)
(* deserialization axiom *)

(*
The kernel of HOL Light does not permit the import of theorems from 
another sessions.  We have two options about how to introduce the import
of functions.  (1) Modify the kernel, or (2) introduce and inconsistency
into HOL Light to allow the creation of arbitrary theorems.

It is not easy to modify the kernel to allow import, because the 
kernel should be nearly the first piece of code to load, and the description
of the import function requires a substantial number of other files to
be loaded beforehand.

We take the approach (2).  However, we restrict the scope of the inconsistency
using the scoping rules of Objective CAML, so that the inconsistency
can only be invoked to create a theorem using mk_deserialization_thm,
which checks that it is a legitimate import.  In other words, 
this is the only
way the inconsistency can be used.

The deserialization axiom is a bit of a hack that uses the fact
that HOL Light does not make a centralized record of the types it creates.
This allows the creation of a boolean term `deserialization`
 that is equivalent to `F`, for which there is no record of this equivalence.
This is what the first lines of mk_deserialize_thm is doing.

We freeze the list of importable theorems at the moment this module loads.
This module cannot be reloaded.

*)
(* ********************************************************************** *)

(* Here is the inconsistency.
   This function can only be called once.
   The "snd" in deserialize removes the negation to create the inconsistency *)

let mk_local_inconsistency() = 
  let pseudo_thm = prove (`(\(x:bool). x) T`,MESON_TAC[]) in
  let abs_rep,rep_abs = Hol.new_basic_type_definition 
    "extern_bool" ("serialize","deserialize") (pseudo_thm) in
  let rep_abs' = MESON[rep_abs] `~(!r. deserialize (serialize r) = r)` in
  let deserialize = new_basic_definition (mk_eq (deserial_var,snd (dest_comb (concl rep_abs')))) in
  let falsehood_thm = UNDISCH (MESON[rep_abs';deserialize] `deserialization ==> r`) in
    falsehood_thm;;

(* XX. need to rework to allow theorems with hypotheses. *)
(* April 27, 2016: we have temporarily removed the list Theorem_digest.digest_list_extern *)

let mk_deserialize_thm = 
  let digest_set = set_of_string 
    ((* Theorem_digest.digest_list_extern @ *) Theorem_nonlinear_digest.digest_list_extern) in
  let rvar = `r:bool` in
    (* The scope of falsehood is restricted here: *)
  let (ok,falsehood_thm) = 
    try (true,mk_local_inconsistency()) with _ -> (false,TRUTH) in
  let mk_dthm t = INST [(t,rvar)] falsehood_thm in
    fun t -> 
      let _ = ok || failwith "mk_deserialization failed" in
      let th = mk_dthm t in 
      let d = try full_digest_thm th with Not_found -> failwith ("digest failed "^string_of_thm th) in
      let _ = St.mem d digest_set || failwith ("theorem digest not found "^d) in
	th;;

let deserialization_axiom = 
  let t = mk_const (deserial,[]) in
    fun () ->
      try
	find (fun u -> t = concl u && hyp u = []) (axioms())
      with _ -> Hol.new_axiom t;;

let has_deserialization_axiom =
  let t = mk_const (deserial,[]) in
    fun () ->
      try
	(find (fun u -> t = concl u && hyp u = []) (axioms()); true)
      with _ -> false;;

let warn_axiom() =
  warn (has_deserialization_axiom()) ("Deserialization axiom installed!");;


let init_serialization () =
( 
  try
    let _ = Sys.getenv "FLYSPECK_SERIALIZATION" in
      true
 with Not_found -> false);;

let use_serialization = ref (init_serialization());;

let mk_ser_thm t = 
  let _ = !use_serialization || failwith "mk_ser_thm" in
  let d = deserialization_axiom() in
    PROVE_HYP d (mk_deserialize_thm t);;

(* ********************************************************************** *)
(* The remaining functions in the module are used to
   load the entire HOL Light session quickly, by skipping
   proofs of theorems that can be imported.

   This code still needs to be cleaned up a bit. *)
(* ********************************************************************** *)


let report_not_found t = 
  if !use_serialization then report ("(-:) "^string_of_term t);;



(*
let des_make_thm p t = 
  try
    let th = mk_ser_thm t in
    let _ = report "(!:)" in 
      th
  with Failure s -> (report_not_found t ;
		     let thm = p t in
		    add_thm thm; thm);;
*)

let des_make_thm = 
  let n = ref 0 in 
    fun p t ->
      try
	let th = mk_ser_thm t in
	let _ = (n := !n + 1) in
	let _ = not(0 = !n mod 20) || (report "(!:)";true) in 
	  th
      with Failure s -> (report_not_found t ;
			 let thm = p t in
			   add_thm thm; thm);;

(*
let des_prove (t,tac) = 
  try 
    let th = mk_ser_thm t in
    let _ = report "(!:)" in
      th
  with Failure s -> (report_not_found t ;
		     let thm = Hol_pervasives.prove(t,tac) in
		    add_thm thm; thm);;
  
let des_prove_by_refinement (t,tacs) = 
    try 
    let th = mk_ser_thm t in
    let _ = report "(!:)" in
      th
  with Failure s -> (report_not_found t ;
		     let thm = Prove_by_refinement.prove_by_refinement(t,tacs) in
		    add_thm thm; thm);;
*)

let des_prove (t,tac) = 
  des_make_thm (fun t -> Hol_pervasives.prove(t,tac)) t;;

let des_prove_by_refinement (t,tacs) = 
  des_make_thm
    (fun t-> Prove_by_refinement.prove_by_refinement (t,tacs)) t;;

let des_MESON thml t = 
  des_make_thm (Hol_pervasives.MESON thml) t;;

let des_ARITH_RULE t = 
  des_make_thm Hol_pervasives.ARITH_RULE t;;

let des_SET_RULE t =
  des_make_thm Hol_pervasives.SET_RULE t;;

let des_REAL_ARITH t = 
  des_make_thm Hol_pervasives.REAL_ARITH t;;

let des_REAL_RING t =
    des_make_thm Hol_pervasives.REAL_RING t;;


(*
mk_deserialize_thm (concl REAL_LE_TRANS);;

let deserialize_all () = 
  let _ = update_database() in
  let some_thml = map (snd) (!theorems) in
  let new_thml =  (map 
		  (fun t -> try mk_deserialize_thm (concl t);
		   with Failure s -> 
		     report ("cannot deserialize: "^(string_of_thm t)); TRUTH)) some_thml in
    filter (fun s -> not (s = TRUTH)) new_thml;;

time deserialize_all();;  (* 1237 secs, 1783 secs. 344 secs. *)
*)

(*
let rec partition_lt pivot l = 
  match l with
      [] -> [],[]
    | h::t -> let less,more = partition_lt pivot t in
	if (h = pivot) then (less,more)
	else if (h < pivot) then (h::less),more
	else less,h::more;;

let rec sort_lt_uniq lis = 
  match lis with
      [] -> []
    | pivot :: rest ->
	let r,l = partition_lt pivot rest in
	  sort_lt_uniq l @ (pivot :: sort_lt_uniq r);;

Sometimes uniq stalls for unclear reasons on this long list...
*)

let deserial_const = mk_const(deserial,[]);;

let is_deserial_const = ((=) deserial_const);;

let deserial_imp t = mk_imp(deserial_const,t);;

let is_deserial_imp t =
  try
    let (a,_) = dest_imp t in
      (is_deserial_const a)
  with Failure _ -> false;;

let if_deserial_axiom =
    if (has_deserialization_axiom()) then deserialization_axiom
    else (fun ()-> TRUTH);;

(*
let deserial_dt gl =
  let g = goal_concl gl in
    if is_deserial_imp g then DISCH_TAC gl else ALL_TAC gl;;

let deserial_un thm =
  if is_deserial_imp (concl thm) then UNDISCH thm else thm;;

let des_prove_explicit(g,tac) =
  let g' = deserial_imp g in deserial_un(
      REWRITE_RULE[if_deserial_axiom()] (prove(g',deserial_dt THEN tac)));;
*)

end;;
